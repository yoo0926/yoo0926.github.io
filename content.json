{"pages":[],"posts":[{"title":"유클리드 호제법","text":"유클리드 호제법(Euclidean algorithm)은 최대공약수, 최소공배수를 구하는 가장 대중적인 알고리즘으로 호제법이란 두 수가 서로 상대방 수를 나누어서 결국 원하는 수를 얻는 알고리즘을 말한다. 2개의 자연수 a,b에 대해서 a를 b로 나눈 나머지를 r이라고 한다면 (단, a&gt;b)a와 b의 최대공야수는 b와 r의 최대공약수와 같다. 이 성질에 따라, b를 r로 나눈 나머지 r’를 구하고, 다시 r을 r’로 나눈 나머지를 구하는 과정을 반복하여 나머지가 0이 되었을 때 나누는 수가 a와 b의 최대공약수이다. 이해하기 쉽게 예를 들어 108과 78의 최대공약수를 구해보면 아래와 같은 연산을 할 수 있다. 108 % 78 = 30 // 큰수를 작은수로 나누고 나머지를 구하기78 % 30 = 18 // 위에서 나눈수(78)를 가져와 위의 나머지로 다시 나눠서 나머지 구하기30 % 18 = 12 // 반복18 % 12 = 612 % 6 = 0 // 나머지가 0이 되면 이때 나눈 수가 최대공약수(=6) 그렇다면 최소공배수는 어떻게 구할까? 최소공배수의 규칙에서 두 수 a,b가 있을 때 a * b = 최대공약수 * 최소공배수 라는 공식이 성립한다. 따라서 주어진 두수를 곱하고 최대공약수로 나눠준다면 그 수가 최소공배수가 될 것이다. 108 * 78 / 6 = 1404 이를 간단하게 코드로 구현해보면 다음과 같다.","link":"/2021/09/02/algo/%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%93%9C-%ED%98%B8%EC%A0%9C%EB%B2%95/"},{"title":"[프로그래머스] 약수의 개수와 덧셈","text":"🔗 출처약수의 개수와 덧셈 : https://programmers.co.kr/learn/courses/30/lessons/77884 📔 문제설명두 정수 left와 right가 매개변수로 주어집니다. left부터 right까지의 모든 수들 중에서, 약수의 개수가 짝수인 수는 더하고, 약수의 개수가 홀수인 수는 뺀 수를 return 하도록 solution 함수를 완성해주세요. ✅ 제한사항 1 ≤ left ≤ right ≤ 1,000 🔍 입출력 예 left right result 13 17 43 24 27 52 📝 풀이어떤 자연수의 약수를 구하는 가장 쉬운 방법은 자연수 N을 i = 1 ~ N 까지 나눠서 나머지가 0으로 나오는 i의 개수를 찾으면 된다. 이러한 경우 최소값 1 ~ 자기자신 N까지 확인하므로 시간복잡도는 O(n) 이 나온다. 더 빠르게여기서 약수의 특성에 대해서 조금 더 생각해 본다면 항상 약수는 그 짝이 되는 수가 존재한다. (ex. 15 = 3 * 5) 즉, N의 약수들 중 두 약수의 곱이 N이 되는 약수 a,b는 반드시 존재하므로 N의 제곱근까지 약수를 구하면 그 짝이 되는 약수는 자동으로 구했다고 볼 수 있다. 이 방법을 사용하여 약수를 구하면 시간복잡도는 O(n^(1/2)) 이 나온다. ➕ 추가프로그래머스에서 올린 해설을 찾아보니 애초에 문제에서 요구하는건 모든 약수를 구하는게 아니라 약수의 개수가 짝수인건 더하고 홀수인건 빼는 것이라서 약수가 홀수인지 짝수인지만 구하면 된다. 약수를 구해보면 약수가 홀수라면 그 수는 약수의 제곱수로 나오므로 매개변수 left ~ right 의 제곱수만 구하면 문제를 풀 수 있다.","link":"/2021/06/10/algo/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EC%95%BD%EC%88%98%EC%9D%98-%EA%B0%9C%EC%88%98%EC%99%80-%EB%8D%A7%EC%85%88/"},{"title":"[프로그래머스] 신규 아이디 추천","text":"🔗 출처 신규 아이디 추천 : https://programmers.co.kr/learn/courses/30/lessons/72410 📔 문제 설명카카오에 입사한 신입 개발자 네오는 “카카오계정개발팀”에 배치되어, 카카오 서비스에 가입하는 유저들의 아이디를 생성하는 업무를 담당하게 되었습니다. “네오”에게 주어진 첫 업무는 새로 가입하는 유저들이 카카오 아이디 규칙에 맞지 않는 아이디를 입력했을 때, 입력된 아이디와 유사하면서 규칙에 맞는 아이디를 추천해주는 프로그램을 개발하는 것입니다.다음은 카카오 아이디의 규칙입니다. 아이디의 길이는 3자 이상 15자 이하여야 합니다.아이디는 알파벳 소문자, 숫자, 빼기(-), 밑줄(_), 마침표(.) 문자만 사용할 수 있습니다.단, 마침표(.)는 처음과 끝에 사용할 수 없으며 또한 연속으로 사용할 수 없습니다.“네오”는 다음과 같이 7단계의 순차적인 처리 과정을 통해 신규 유저가 입력한 아이디가 카카오 아이디 규칙에 맞는 지 검사하고 규칙에 맞지 않은 경우 규칙에 맞는 새로운 아이디를 추천해 주려고 합니다.신규 유저가 입력한 아이디가 new_id 라고 한다면, 1단계 new_id의 모든 대문자를 대응되는 소문자로 치환합니다.2단계 new_id에서 알파벳 소문자, 숫자, 빼기(-), 밑줄(_), 마침표(.)를 제외한 모든 문자를 제거합니다.3단계 new_id에서 마침표(.)가 2번 이상 연속된 부분을 하나의 마침표(.)로 치환합니다.4단계 new_id에서 마침표(.)가 처음이나 끝에 위치한다면 제거합니다.5단계 new_id가 빈 문자열이라면, new_id에 “a”를 대입합니다.6단계 new_id의 길이가 16자 이상이면, new_id의 첫 15개의 문자를 제외한 나머지 문자들을 모두 제거합니다. 만약 제거 후 마침표(.)가 new_id의 끝에 위치한다면 끝에 위치한 마침표(.) 문자를 제거합니다.7단계 new_id의 길이가 2자 이하라면, new_id의 마지막 문자를 new_id의 길이가 3이 될 때까지 반복해서 끝에 붙입니다. 신규 유저가 입력한 아이디를 나타내는 new_id가 매개변수로 주어질 때, “네오”가 설계한 7단계의 처리 과정을 거친 후의 추천 아이디를 return 하도록 solution 함수를 완성해 주세요. ✅ 제한사항 new_id는 길이 1 이상 1,000 이하인 문자열입니다.new_id는 알파벳 대문자, 알파벳 소문자, 숫자, 특수문자로 구성되어 있습니다.new_id에 나타날 수 있는 특수문자는 -_.~!@#$%^&amp;*()=+[{]}:?,&lt;&gt;/ 로 한정됩니다. 🔍 입출력 예 no new_id result 예1 \"...!@BaT#*..y.abcdefghijklm\" \"bat.y.abcdefghi\" 예2 \"z-+.^.\" \"z--\" 예3 \"=.=\" \"aaa\" 예4 \"123_.def\" \"123_.def\" 예4 \"abcdefghijklmn.p\" \"abcdefghijklmn\" 📝 풀이정규식을 사용하면 어렵지 않게 풀 수있는데 정규식을 자주 쓰진 않아서 자세한 규칙들은 블로그를 검색해보고 정규식 검증은 https://regexr.com에서 진행했다.","link":"/2021/05/09/algo/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EC%8B%A0%EA%B7%9C-%EC%95%84%EC%9D%B4%EB%94%94-%EC%B6%94%EC%B2%9C/"},{"title":"Angular 개요","text":"회사 프론트엔드가 Angular로 되어있는데 이쪽을 메인잡으로 일하진 않지만 프론트 개발자를 많이 채용해서 완전히 업무를 분리하기 전까지 이쪽도 어느정도 할줄 알아야 할거같아서 Angular에 대해서 공부하면서 간단히 정리해보자 Angular❓Angular는 Google에서 만든 **SPA(Single Page Application)**방식의 프론트엔드 개발을 위한 자바스크립트 프레임워크 이다. 개발언어로 es6, Dart 등을 지원하기도 하지만 공식적으로 TypeScript를 권장하고 있다. Angular 1.x 버전을 AngularJS, Angular 2 이상 버전을 Angular 라고 부른다. AngularJS와 Angular는 하위 호환성이 없는 브레이킹 체인지를 다수 포함하여 큰 차이점이 많은데 몇가지 정리를 하자면 Controller와 $scope 기반에서 컴포넌트 기반 개발(CBD, Component Based Development)로 전환되었다. 이전보다 향상된 모듈 시스템과 DOM 제어 기능을 제공하며 API가 단순화 되었다. 주력 개발언어로 TypeScript를 도입하여 대규모 개발에 적합한 정적타입과 인터페이스, 제네릭 등 타입체크지원 기능을 제공한다. ECMAScript6에서 새롭게 도입된 모듈, 클래스, ECMAScript7의 데코레이터를 지원한다. 간단한 명령어로 개발환경을 지원하여 프로젝트 스케폴딩을 생성, 실행, 빌드할 수 있는 Angular CLI를 제공한다. Angular 장점👍 컴포넌트 기반의 기능에 따라 코드분리와 재사용성이 쉬운 장점이 있다. SPA방식으로 다른 페이지로의 전환 속도가 빠르다. 프레임워크로서 개발에 필요한 대부분의 기능을 탑재하고 있다. Angular 단점👎 TypeScript를 주언어로 사용하여 이에 대한 학습이 필요하고 추가로 Angular의 여러 개념들과 기능들을 익혀야 하는만큼 학습량이 높은 편이다. 웹페이지가 모두 로딩된 이후 전환은 빠른편이지만 초기 로딩 시 느린 편이다. 검색엔진 최적화가 잘 되지 않아서 구글을 제외한 다른 사이트들에서 제대로 수집되지 않는 경우가 있다고 한다.","link":"/2021/11/13/angular/%EA%B0%9C%EC%9A%94/"},{"title":"카카오톡 오픈그래프 캐시 삭제 방법","text":"블로그 대표 이미지를 변경했음에도 카카오톡에 공유 시 기존 이미지가 계속 나오는 문제가 있었다. 사이트의 소스코드의 태그를 확인해봐도, 오픈그래프 적용을 확인해볼수 있는 페이스북의 Sharing Debugger 사이트에서도 확인했을 때 문제가 없었으니 카카오에서 이미지 캐시가 문제라고 생각되서 구글링을 해봤고 역시 삭제하는 방법을 찾을 수 있었다. 삭제방법 카카오 개발자 사이트의 초기화 도구에서 OG(Open Graph) 캐시로 들어간다. 개발자 계정이 없다면 카카오 계정으로 간단하게 가입하고 있으면 로그인 삭제하려는 URL을 입력하고 초기화 한다. 이제 다시 카카오톡에 링크를 공유해보면 바뀐 이미지가 나오는걸 확인할 수 있다. 참고로 open graph 라는건 html 메타 태그의 종류 중 하나로 사용자가 링크를 sns의 입력창에 입력하면 크롤러가 미리 그 웹사이트를 방문해서 HTML head의 오픈그래프 메타 데이터를 긁어온다. og:title, og:description, og:image 등 태그의 데이터를 바탕으로 미리보기 이미지와 설명을 만들어서 보여주게 된다.","link":"/2021/11/21/blog/ogimage-reset/"},{"title":"Github Page와 Hexo를 활용하여 블로그 개설하기","text":"블로그를 시작하며그동안 OneNote, Notion 등 노트프로그램을 사용하여 단편적으로 공부하던 내용을 블로그를 통해 좀 더 체계적으로 정리하고 다른사람들과 공유하고 싶은 생각에 블로그를 시작하기로 했다.(끈기가 부족한 편이라 얼마나 갈진 모르겠다^^;;) 일반적인 블로그를 생각하면 네이버 블로그, 티스토리, 혹은 미디엄, 브런치 등을 떠올릴 수 있지만 기술블로그를 표방하는만큼 github page를 이용하기로 마음먹었다. github page에서는 username.github.io 도메인을 무료로 제공하여 정적 웹페이지를 무료 호스팅해주고 있다. github page에서 사용할 정적 웹페이지 생성기는 생각보다 다양한 종류가 있지만 마크다운 문서를 지원하면서 국내에서 가장 많이 사용되는 두가지는 다음과 같다. Jekyll Ruby 기반 다양한 테마, 플러그인 지원 환경설정 및 커스터마이징이 다소 복잡하며(특히 윈도우에서) 글이 많아지면 빌드속도가 느려진다는 이야기가 있다. Hexo Javascript(Node.js) 기반 마찬가지로 다양한 테마, 플러그인 지원 npm을 통해 쉽게 설치 가능하며 Github 배포과정도 편하다. 처음엔 Jekyll을 사용하여 초기설정을 해봤는데 윈도우에서 설정이 너무 복잡하고 오류도 많이나서 익숙한 Node.js기반의 Hexo로 시작하기로 했다. 1. 설치1.1 사전준비 Node.js 설치 Git 설치 Github 가입 후 신규 Repository 2개 생성 각 프로그램 설치는 이미 많은 문서들이 있기 때문에 별도로 언급하진 않겠다. Repository를 2개 생성하는 이유는 각각 블로그 운영, hexo 설정을 저장할 목적이며 블로그로 운영할 Repository name은 USERNAME.github.io 의 Public으로 생성한다. 2. Hexo 설치 및 블로그 생성Hexo설정을 저장할 github repository를 clone 한 후 해당 위치에서 작업한다. 1234npm install -g hexo-clihexo init $디렉토리명cd $디렉토리명npm install 2.1 설정파일 수정블로그 생성이 정상적으로 완료되었으면 이제 설정파일을 수정해보자. root 경로에 _config.yml파일을 확인할 수 있는데 기본적인 블로그 설정은 이곳에서 관리한다. 자세한 내용은 공식문서에서 확인할 수 있다. Hexo Docs : https://hexo.io/docs/ Site 설정블로그 이름 및 간략한 소개를 설정한다. 12345title: Hello Worldsubtitle: No pain, No gaindescription:author: Jaeyong Yoo... URL 설정블로그 URL 정보를 설정한다. 1234url: https://USERNAME.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults: Github 설정배포할 Github Page의 Repository 정보를 입력한다. 123deploy: type: git repo: https://github.com/yoo0926/yoo0926.github.io 정상적으로 설치와 설정이 끝났다면 아래 명령어로 서버를 실행시켜 웹브라우저에서 http://localhost:4000 으로 접속하여 확인할 수 있다. 1hexo server #or hexo s 만약 로컬에서 실행 시 permission denied 가 발생하는 경우가 있다면 그냥 port를 변경해서 테스트하자 1hexo server -p 8088 3. Github에 배포하기로컬에서 테스트가 완료되었다면 이제 앞서 언급한 Github Page의 정적 웹페이즈 호스팅을 사용해보자. Hexo Generate and Deploygithub에 배포하기 위해선 hexo-deployer-git 이라는 플러그인을 설치해야 한다. 1npm install hexo-deployer-git 플러그인 설치가 완료되면 배포할 리소스를 생성하여 앞서 _config.yml 파일에서 설정한 배포설정의 저장소로 배포하게 된다. 1234hexo generate #hexo ghexo deploy #hexo d#동시에 하고 싶으면hexo deploy --generate #hexo d -g 생성된 리소스는 USERNAME.github.io 저장소에 배포되며 https://USERNAME.github.io로 접속하게되면 블로그를 확인할 수 있다. 주의간혹 deploy가 정상적으로 되지 않는다면 아래 명령어로 clean 후 다시 배포를 해보자. 12hexo cleanhexo d -g 이상으로 기본적인 블로그 생성과 관련된 내용을 마무리 한다. 추가메모 12hexo new 포스트명 //기본설정값 draft 로 바꿔놓음hexo publish 포스트명 //draft -&gt; posts 로 이동 ReferenceHexo로 github 블로그 만들기 (Hueman 테마)Github Page와 Hexo를 통해 30분만에 기술 블로그 만들기Hexo 공식문서","link":"/2020/11/01/blog/start-blog/"},{"title":"함수형 프로그래밍 - 개요","text":"함수형~ 함수형~ 여러 곳에서 이야기는 종종 들었지만 제대로 찾아본 적이 없다보니 기본적인 개념부터 많이 부족해서 간단히 스터디를 시작했다. 특정 언어를 선정해서 언어적 특성에 종속되기 보단 우선 함수형 프로그래밍의 패러다임에 대해서 먼저 학습 해보자. 개요함수형 프로그래밍은 크게 두 그룹으로 분류된다. 구분 지원범위 언어 순수 함수형 언어 오직 함수형 패러다임만 지원 Haskell 불순 함수형 언어 함수형 패러다임과 명령형 프로그래밍을 지원 LISP 그럼 여기서 명령형은 뭐고 함수형 패러다임은 뭘 말하는 걸까? 프로그래밍 패러다임은 크게 보면 2가지로 분류할 수 있다. 명령형 프로그래밍 : 프로그래밍의 상태와 상태를 변경시키는 구문의 관점에서 연산을 설명하여 기능을 구현하기 위한 알고리즘을 명시하지만 결국 무엇을 해야하는지는 명시하지 않는다. 절차지향 프로그래밍 : 수행되어야 할 연속적인 계산 과정을 포함 (C, C++) 객체지향 프로그래밍 : 객체들의 집합으로 프로그램의 상호작용을 표현 (C++, Java, C#) 선언형 프로그래밍 : How(어떻게) 보단 What(무엇을) 해야하는지 설명하는 방식으로 알고리즘에 대해서 명시하진 않고 목표를 명시한다. 함수형 프로그래밍 : 순수 함수를 조합하고 소프트웨어를 만드는 방식 (Clojure, Haskell, LISP) 명령형 프로그래밍은 어떻게 할 것이가(How)를 표현하고, 선언형 프로그래밍은 무엇을 할것인가(What)를 표현한다. 특성함수형 프로그래밍은 아래와 같은 특징을 같는다. 계산을 수행하기 위해 조건식과 재귀를 사용하는 수학 함수의 개념에 따라 설계되었다. 고차함수high order function와 지연연산lazy evaluation 기능을 지원한다. 고차 함수 람다 계산법에서 만들어진 용어로 아래 조건을 만족하는 함수 함수에 함수를 파라미터로 전달할 수 있다. 함수의 반환값으로 함수를 사용할 수 있다. 고차 함수는 1급 함수의 부분집합이다. 지연 연산 불필요한 연산을 피하기 위해서 결과값이 필요한 시점까지 연산을 늦추는 것을 말한다. 값을 미리 계산해서 저장하지 않기 때문에 메모리의 효율적인 사용이 가능 루프문과 같은 흐름제어와 If-Else, Switch문과 같은 조건문을 지원하지 않고 함수와 함수호출을 직접 사용한다. OOP와 마찬가지로 추상화, 캡슐화, 상속, 다형성과 같은 개념을 지원한다. 장점 Bugs-Free Code : State를 지원하지 않으므로 부작용이 없어서no side-effect 오류없는 코드작성이 가능하다.(없다기 보단 그냥 적은게 맞을 것 같다.) 효율적인 병렬 프로그래밍 : 상태 변경이 없기 때문에 병렬로 작동하도록 기능에 대해서 프로그래밍할 수 있으며 이는 재사용 및 테스트를 더 쉽게 지원한다. 효율성 : 독립적인 유닛으로 구성되서 동시에 실행할 수 있다. 중첩 함수 지원 : 중첩함수를 지원한다. 지연 연산 : Lazy List, Lazy Map 등과 같은 지연 함수 구조를 지원한다. 단점 큰 메모리 공간이 필요하며 상태가 없기 때문에 작업을 수행할 때마다 새 객체를 만들어야한다. 함수형 vs 객체지향 함수형 OOP 불변 데이터 사용 가변 데이터 사용 선언적 프로그래밍 모델 명령형 프로그래밍 모델 무엇을 하는가에 초점 어떻게 하는가 에 초점 병렬 프로그래밍 지원 병렬 프로그래밍에 적합하지 않음 부작용이 없다 부작용이 발생할 수 있다. 함수 호출 및 재귀를 사용하여 흐름 제어 루프와 조건문을 사용하서 흐름 제어 재귀를 사용한 반복 루프를 사용한 반복 실행순서가 중요하지 않다. 실행 순서가 매우 중요하다. 데이터 추상화, 동작 추상화 지원 데이터 추상화만 지원 이상으로 함수형 프로그래밍에 대한 대략적인 개요에 대해서만 우선 정리해 보았다. Reference tutorialspoint - Lean Functional Programming 함수형 프로그래밍 요약 함수형 프로그래밍 언어에 대한 고찰","link":"/2020/12/07/functional/%EA%B0%9C%EC%9A%94/"},{"title":"함수형 프로그래밍 - 재귀","text":"앞서 확인한 개요에서 언급했는데 함수형 프로그래밍에선 반복을 재귀를 통해서 구현한다고 했는데 재귀와 꼬리재귀에 대해서 간단히 알아보자. 재귀함수 본문에서 자기자신을 호출하는 방식을 재귀호출(recursive call)이라고 부른다. 재귀는 다른 명령어가 방지할 때까지 계속된다. 예제 꼬리 재귀 최적화 in python재귀호출의 경우 호출 스택의 깊이가 얕은 경우엔 큰 상관이 없으나 깊이가 깊어지면 오버플로우가 발생하는 문제가 있다.여담으로 실행하는 시스템에 따라서 조금씩 다를수 있지만 파이썬에서 호출가능한 스택의 최대 깊이는 보통 1000 정도에서 RecursionError가 발생한다. 이를 해결하기 위한 방법으로 제시되는 해결책 중 하나가 꼬리 재귀Tail recursion이다. 간단히 말하자면 함수에서 마지막으로 호출하는 함수가 자기 자신이고, 재귀 호출의 값을 반환받은후 추가적인 연산이 필요하지 않는 방식을 말한다. 꼬리 재귀 적용 예제위의 예제에서 사용한 팩토리얼 함수를 보자. fact(n)을 호출했을 때 연산이 끝나지 않았는데 fact(n-1)을 호출하기 때문에 리턴 주소를 저장하기 위해서 시스템 콜스택을 사용하게 된다. 즉, 현재 함수(fact(n))에서 결과값을 반환하기 위해서는 현재 함수의 인자 값(n)을 스택에 가지고 있다가 그 다음 호출될 함수(fact(n-1))의 결과 값과 함께 연산을 해야 한다는 점이다.이러한 방식은 꼬리 재귀를 만족하지 못한다고 본다. 예제를 꼬리 재귀로 바꾸려면 어떻게 해야할까? 재귀를 호출하는 부분에서 추가적인 연산이 필요없도록 만들면 되는데 이를 구현하기 위해선 return에서는 (언어 스펙에서 지정한 스택에 메모리를 쌓지 않는 연산자를 제외한) 연산자를 사용하면 안된다. 연산자의 사용없이 재귀 호출의 반환값을 그대로 return 해주면 된다. 한가지 주의할 점은 개발자가 꼬리재귀 구조로 코드를 짜더라도 사용하는 언어의 스펙에 따라서 꼬리재귀 최적화 보장여부가 다르기 때문에 확인이 필요하다.요즘 python을 공부하고 싶어서 위 예시를 python으로 들었지만 python은 꼬리재귀 최적화를 보장하지 않는데 python의 창시자 귀도 반 로섬의 의견은 다음과 같다. 귀도 반 로섬의 TRE(Tail Recursion Elimination)에 대한 반론 콜 스택을 추적하기에 부적합하다(디버깅이 어렵다) 단순 최적화기 때문에 개별 파이썬 컴파일러 구현체에서 선택하게 둘 것 재귀가 모든 것의 기반이라는 접근은 이상적인 수학적인 접근일 뿐이다 파이썬 스타일의 개발자들은 재귀 대신 멋진(?) 문법들을 쓸 수 있다 not PYTHONIC 하다 Reference tutorialspoint - Learn Functional Programming 재귀,반복, Tail Recursion Tail Recursion Elimination","link":"/2020/12/07/functional/%EC%9E%AC%EA%B7%80/"},{"title":"기술면접 준비(Java)","text":"내용은 기초적인 부분이지만 막상 면접 전에 한번이라도 정리하지 않으면 용어가 바로바로 안나오는 경우도 많기 때문에 간단하게나마 정리해 보았다. OOP란객체지향 프로그래밍(Object-Oriented Programming, OOP)은 컴퓨터 프로그램을 명령어의 목록으로 보는 시각에서 벗어나 여러 개의 독립된 단위, 즉 “객체”들의 모임으로 파악하고자 하는 것 입니다. 각각의 객체는 메시지를 주고받고, 데이터를 처리할 수 있으며 대표적인 특징으로 추상화, 상속, 캡슐화, 다형성이 있습니다. 직렬화(serialization)란?객체 또는 데이터를 스트림을 통해 입출력하려면 바이트(byte)형태로 변환하는 것이 필요한데, 이를 직렬화 라고 합니다. 반대로 스트림을 통해 받은 직렬화된 객체를 원래 모양으로 만드는 과정을 역직렬화라고 합니다. 박싱과 언박싱이란?기본 자료형(Primitive data type)을 Wrapper class로 바꾸어 주는 것을 박싱, **Wrapper class를 기본 자료형(Primitive data type)**으로 바꿔주는 것을 언박싱 이라고 합니다. Static에 대해서 static 키워드를 쓰면 객체를 생성하지 않아도 static 변수나 static 함수를 사용할 수 있습니다. 인스턴스를 생성하면 각 인스턴스는 서로 독립적이기 때문에 서로 다른 값을 유지합니다. 각 인스턴스들이 공통적으로 같은 값이 유지되어야 하는 경우 static을 붙입니다. static 이 붙은 메서드 에서는 인스턴스 변수를 사용할 수 없습니다. 메서드 내에서 인스턴스 변수를 쓰지 않는다면 가능하면 static을 붙이는게 호출 시간이 짧아지기 때문에 효율이 높아집니다. 클래스 설계시 static 사용 지침 클래스의 멤버변수 중 모든 인스턴스에 공통된 값을 유지해야 하는 것이 있으면 static 을 사용합니다. 메서드 중에서 인스턴스 변수를 사용하지 않는 메서드는 static 을 사용하는 것을 고려합니다. 접근 제어자에 대해서 public : 어디서든 접근 가능 protected : 동일 패키지 혹은 상속받은 외부 패키지 클래스에서 사용 (default) : 동일 패키지 내에서만 접근 가능 private : 해당 클래스 내에서만 접근 가능 String vs StringBuffer vs StringBuilder String immutable(불변) 객체를 한 번 할당할시 메모리 공간에 변동이 없습니다. 동기화를 신경쓰지 않아도 됩니다. 엄청나게 많은 문자열을 선언 및 연산할 시 성능저하를 고려해야합니다. StringBuffer mutable(가변) 멀티스레드 환경에서도 동기화를 지원(Thread-safe) StringBuilder mutable(가변) 동기화를 지원하지 않습니다. 정리하면 적은 양의 문자열의 선언 후 연산이 필요없다면 String을 사용하고 문자열의 선언이 많이 필요하거나 연산이 필요한데 싱글스레드 환경이라면 StringBuilder를, 멀티스레드 환경이라면 StringBuffer를 사용합니다. Java8 특징은?java에 함수형 프로그래밍이 처음으로 도입된 버전으로 새로 도입된 주요 기능으론Lamda 표현식, Stream API, Optional Class 같은 게 있습니다. 람다(Lamda) 표현식 익명함수로 이름과 식별자가 없는 함수를 말합니다. 불필요한 코드를 줄이고 가독성을 향상시키기 위함입니다. 12List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.forEach(num -&gt; System.out.println(&quot;number : &quot; + num)); StreamAPI 람다식을 적용해서 컬렉션같은 데이터 처리연산을 하기 위한 api로 멀티 스레드를 활용해서 병렬로 연산을 수행할 수 있고, 원본 데이터를 변경하지 않는 특징이 있고 코드가 매우 간단해진다는 것을 알 수 있습니다. Optional Class util 패키지에 속하며 NullPointException을 관리하기 위해 null이 될 수 있는 객체를 감싸고 있는 래퍼 클래스입니다. 명시적으로 해당 변수가 null일 수 있음을 표현하면서 null 체크를 직접하지 않아도 됩니다. 아래는 일반적으로 많이 사용되는 optional 예제코드 1234@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; { Optional&lt;UserEntity&gt; findByName(String Name);} 123String name = &quot;jay&quot;;UserEntity optUserEntity = userRepository.findByName(name) .orElseThrow(() -&gt; new EmptyDataException(&quot;해당 이름을 가진 유저가 없습니다.&quot;)); try-with-resource란?try-with-resources는 java7 이후 추가되었으며 자동으로 자원을 해제해주는 기능입니다.try 구문에 AutoCloseable 인터페이스를 구현하는 객체를 리소스로 선언하고 사용이 끝나면 자동으로 close 해주는 기능입니다. 123456try (Scanner scanner = new Scanner(new File(&quot;newFile.txt&quot;))){ System.out.println(scanner.nextLine());} catch (FileNotFoundException e) { e.printStackTrace();} 오버로딩 오버라이딩 차이점은?자바에서 다형성을 지원하는 방법으로 오버로딩과 오버라이딩이 있습니다. (다형성(polymorphism) : 하나의 객체가 여러타입을 가지는 것) 오버로딩(Overloading)은 같은 이름의 메소드를 여러 개 가지면서 매개변수의 유형과 개수가 다르도록 작성하여 다양한 유형의 호출에 응답하도록 하는 것입니다. 프로그램의 가독성 ⬆ 오버라이딩(Overriding)은 상위클래스가 가진 메소드를 자식클래스에서 재정의 하여 사용하는 것을 말합니다. 하나의 코드로 여러 객체를 처리할 수 있는 장점이 있어서 사용 명칭 메소드명 매개변수 리턴타입 오버로딩 같음 다름 같아도되고 달라도됨 오버라이딩 같음 같음 같아야함 HashMap, LinkedHashMap, TreeMap 비교 HashMap 내부적으로 Entry의 array로 되어있고 해당 array에 index는 내부 해쉬 함수를 통해 계산합니다. hashing을 사용하기 때문에 많은 양의 데이터를 검색하는데 뛰어난 성능을 가지고 있지만 내부 해시값에 따라서 키순서가 정해져서 특정 순서나 규칙없이 출력됩니다. LinkedHashMap 내부적으로 LinkedList 형태로 저장되며 입력된 데이터의 순서를 유지할 수 있습니다. HashMap과 기본적으로 기능은 동일하지만 순서를 유지하는 기능이 추가되면서 메모리 사용량이 더 높습니다. TreeMap Key값에 따라서 자동으로 Sort가 되는 방식이며 동기화(synchronized) 처리가 되어있어 Thread-safe 합니다. HashMap과 다르게 키값으로 null을 허용하지 않고 내부적으로 red black tree 구조로 데이터를 저장합니다. red black tree 는 기존의 이진트리의 각 노드에 색깔을 저장하는 공간을 추가해서 색깔을 기준으로 균형을 맞추는 트리입니다. 키값에 대한 Compartor(콤퍼레이터) 구현으로 정렬 순서를 변경할 수 있습니다. 정리하자면 특별한 사유가 없다면 검색성능이 가장 좋은 HashMap 사용 순서를 보장하고 싶다면 LinkedHashMap 사용 키값을 일정하게 iterate 하고자한다면 TreeMap 사용 interface vs abstract 공통점 선언만 있고 구현 내용이 없습니다. 스스로 객체를 생성할 수 없지만 추상클래스를 extends 받거나, interface를 implements한 자식들만 객체를 생성할 수 있습니다. interface(인터페이스) 다중 상속 가능 추상 메서드, 상수만 선언 가능(java8부터 default메서드 사용 가능) 생성자, 일반 변수를 가질 수 없음 서로 관련성이 없는 클래스들이 인터페이스를 구현하게 되는 경우 특정 데이터 타입의 행동을 명시하고 싶은데, 어디서 구현되든지 상관없을 때 다중상속을 허용하고 싶을 때 abstract(추상 클래스) 다중 상속 불가 추상 메서드 1개 이상, 일반 변수, 일반 메서드 선언 가능 생성자, 일반 변수 가질 수 있음 관련성이 높은 클래스간에 코드를 공유하고 싶은 경우 상속받은 클래스들이 공통적으로 가지는 메서드와 필드가 많거나, public 이외의 접근제어자 사용이 필요한 경우 사용할 수 있습니다. 자바 메모리 구조 메서드(Method) 영역클래스 변수의 이름, 타입, 접근 제어자 등과 같은 클래스와 관련된 정보를 저장하며 static 변수, 전역변수 등이 저장된다.코드에서 사용되는 클래스들을 로더가 읽고 클래스 별로 분류해서 저장합니다. 스택(Stack) 영역메서드가 실행되면 스택 영역에 메소드에 대한 영역이 1개 생기며 여기에 지역변수, 매개변수, 리턴값 등이 저장된다. LIFO(Last In First Out) 방식의 메모리입니다. 힙(Heap) 영역new 연산자를 통해 생성된 객체와 배열의 인스턴스를 저장되고, 메모리는 가비지 컬렉터에 의해 관리됩니다.","link":"/2021/08/21/interview/technical-1/"},{"title":"Git-flow의 활용","text":"회사에서 내부서버에 Gitlab을 활용하여 Git Server를 구축하여 형상관리를 하고 있는데 특별한 관리나 체계없이 브랜치 관리를 하다보니 히스토리 파악하기도 힘들기도 하고 형상관리를 제대로 하고 있다는 느낌이 들지 않아 효율적인 형상관리 시스템의 사용을 위하여 방법을 찾던 중 우아한형제들 기술블로그의 “우린 Git-flow를 사용하고 있어요” 라는 글을 보고 해당 전략을 도입하면서 각 브랜치에 대해 간략하게 정리를 해보았다. Git-flow에는 5가지 종류의 브랜치가 존재한다. 항상 유지되는 메인 브랜치들(master, develop)과 일정 기간 동안만 유지되는 보조 브랜치들(feature, release, hotfix)이 있다. master : 제품으로 출시될 수 있는 브랜치 develop : 다음 출시 버전을 개발하는 브랜치 feature : 기능을 개발하는 브랜치 release : 이번 출시 버전을 준비하는 브랜치 hotfix : 출시 버전에서 발생한 버그를 수정 하는 브랜치 가장 중심이 되는 브랜치는 master랑 develop 브랜치이며, 이 두 개 브랜치는 무조건 있어야 한다. 이름은 바뀔 수 있다만 웬만해서는 변경하지 않고 진행하도록 하자. Git도 Production에서 사용하는 브랜치는 master를 사용하게 되니 관련된 부분을 변경하면 새로운 사람이 왔을때 스터디 커브가 존재할 수 있다. 병합된 feature, release, hotfix 브랜치는 삭제하도록 한다. (클라이언트 툴에서 git flow제공한다면 merge 하면 삭제하는 옵션을 제공한다.) Feature 브랜치 브랜치 나오는 곳 : develop 브랜치가 들어가는 곳 : develop 이름 지정 : master, develop, release-*, hotfix-*를 제외한 어떤 것이든 가능. 새로운 기능을 추가하는 브랜치이다.feature브랜치는 origin에는 반영하지 않고, 개발자의 reop애만 존재하도록 한다. 여기서 머지를 할 때, --no-ff 옵션을 이용하여 브랜치에서 머지가 되었음을 git 기록에 남겨두도록 한다. Release 브랜치 브랜치 나오는 곳 : develop 브랜치가 들어가는 곳 : develop, master 이름 지정 : release-* 새로운 Production 릴리즈를 위한 브랜치이다.지금까지 한 기능을 묶어 develop 브랜치에서 release 브랜치를 따내고, develop 브랜치에서는 다음번 릴리즈에서 사용할 기능을 추가한다.release 브랜치에서는 버그 픽스에 대한 부분만 커밋하고, 릴리즈가 준비되었다고 생각하면 master로 머지를 진행한다. (이때도 --no-ff 옵션을 이용하여 머지하였음을 남긴다.)master로 머지 후 tag 명령을 이용하여 릴리즈 버전에 대해 명시를 하고, -s 나 -u &lt;key&gt; 옵션을 이용하여 머지한 사람의 정보를 남겨두도록 한다. 그런 뒤 develop 브랜치로 머지하여, release 브랜치에서 수정된 내용이 develop 브랜치에 반영한다. Hotfix 브랜치 브랜치 나오는 곳 : master 브랜치가 들어가는 곳 : develop, master 이름 지정 : hotfix-* Production에서 발생한 버그들은 전부 여기로… 수정 끝나면, develop, master 브랜치에 반영하고, master에 다가는 tag 를 추가해준다.만약 release 브랜치가 존재한다면, release 브랜치에 hotfix 브랜치를 머지하여 릴리즈 될 때 반영이 될 수 있도록 한다. Reference우아한형제들 기술블로그의 “우린 Git-flow를 사용하고 있어요”","link":"/2020/11/02/git/git-flow/"},{"title":"Spring Framework란 무엇인가","text":"기초가 부족한 관계로 기초부터 다시 정리도 하는 겸사겸사 첫주제는 spring framework로 정했다. Srping Framework란 스프링 프레임워크(Spring Framework)는 자바 플랫폼을 위한 오픈 소스 애플리케이션 프레임워크로 간단히 스프링(Spring)이라고도 한다. 동적인 웹 사이트를 개발하기 위한 여러 가지 서비스를 제공하고 있다. 대한민국 공공기관의 웹 서비스 개발 시 사용을 권장하고 있는 전자정부 표준프레임우커의 기반 기술로서 쓰이고 있다. 특징 크기와 부하의 측면에서 경량 컨테이너로서 자바 객체를 직접관리한다. 객체 생성, 소멸과 같은 라이프 사이클을 관리하며 스프링으로부터 필요한 객체를 얻어올 수 있다 제어 반전 혹은 제어 역행(IoC: Inversion of Control)을 지원한다. 컨트롤의 제어권이 사용자가 아닌 프레임워크에 있어서 필요에 따라 스프링에서 사용자의 코드를 호출한다. IoC는 DI와 DL에 의해 구현된다. DL(Dependency Lookup) : 의존성 검색 컨테이너에서는 객체들을 관리하기 위해 별도의 저장소에 빈을 저장하는데 저장소에 저장되어 있는 개발자들이 컨테이너에서 제공하는 API를 이용하여 사용하고자 하는 빈을 검색하는 방법 DI(Dependency Injection) : 의존성 주입 의존성 주입이란 객체가 서로 의존하는 관계가 되게 의존성을 주입하는 것으로 객체지향 프로그램에서 의존성이란 하나의 객체가 어떠한 다른 객체를 사용하는 것을 의미한다. IoC에선 각 클래스 사이에 필요로 하는 의존관계를 빈 설정 정보를 바탕으로 컨테이너가 자동으로 연결해 주는 것을 말한다. POJO(Plain Old Java Object) 방식의 프레임워크이다. 직역하면 오래된 방식의 간단한 자바 오프젝트라는 말이다. 일반적인 J2EE 프레임워크에 비해 구현을 위하여 특정한 인터페이스를 구현하거나 상속을 받을 필요가 없어 기존에 존재하는 라이브러리 등을 지원하기에 용이하고 객체가 가볍다. 쉽게 이야기하면 getter/setter 메소드로 이루어진 Java Benas를 생각하면 된다. 예를 들어 자바 서블릿 코드를 작성할 때는 보통 HttpServlet을 상속받아야 한다. 123public TestServlet extends HttpServlet { ...} 이처럼 서블릿 프로그래밍을 하는 것만으로 객체지향 프로그래밍의 가장 핵심적인 기능 중 하나인 상속을 할 수 없고 HttpServlet에서 제공하는 기능을 어떻게 재사용할 것인지 판단해야하는 부분도 생겼다. POJO는 이러한 제약이 없는 일반적인 객체를 말하는데 여기서 상속이나 인터페이스 구현을 사용하지 않는 객체가 아니라 어떠한 라이브러리나 프레임워크 등 자바 언어 사양 외에 어떠한 제한을 강제받지 않는 자바 오브젝트를 뜻하는 것이다. 관점 지향 프로그래밍(AOP: Aspect Oriented Programming)을 지원한다. 기존의 객체지향 프로그래밍(OOP: Object Oriented Programming) 에서는 객체의 재사용으로 인해 반복되는 코드의 양을 줄일 수 있었지만 여전히 많은 부분에서 중복된 코드가 발생한다. 예를 들어 로그, 권한 체크, 인증, 예외 처리와 같은 소스상에서 반복될 수 밖에 없는 필수적인 요소들로 코드의 가독성이나 유지보수적인 측면에서 좋지 않았다. AOP는 OOP를 대체하는 개념이 아닌 OOP를 좀 더 OOP처럼 사용하기 위하여 보완하는 개념으로 공통적으로 반드시 필요하지만 중복해서 작성해야하는 핵심 이외의 코드들을 외부로 분리하여 관리한다. 이렇게 외부에서 관리하는 공통기능을 핵심 로직에 영향을 끼치지 않게 잘 끼워넣어 개발하면 무분별하게 중복되는 코드를 제거하면서 공통기능의 수정을 통해 모든 핵심 로직의 공통기능을 수정하여 효율적인 유지보수가 가능해지면서 재활용성이 극대화된다. 즉, 위에서 예를 들었던 트랜잭션이나 로깅, 보안과 같이 여러 모듈에서 공통적으로 사용하는 기능의 경우 분리하여 관리할 수 있다는 것이다. MVC (Model2) MVC는 Model, View, Controller 를 뜻하며 사용자 인터페이스와 비즈니스 로직을 분리하여 개발하는 것으로 웹 프로그래밍 개발에선 거의 표준처럼 사용되고 있으며 일반적으로 Model2를 지칭한다. Model은 데이터를 처리하는 영역 View는 렌더링되서 실제로 보이는 화면 Controller는 사용자의 요청을 받고, 응답을 주는 로직을 담당 이처럼 소스를 분리하여 각 소스의 목적을 명확히하면 모듈화를 통해 재사용성을 늘리고 유지보수를 쉽게 할 수 있으며 확정성도 좋은 장점이 있다. 간단한 흐름을 살펴보면 요청 -&gt; 컨트롤러 -&gt; 모델 -&gt; 컨트롤러 -&gt; 뷰 의 흐름이라고 생각하면 된다.(MVC와 관련된 자세한 내용은 추후 기회가 된다면 별도로 포스트하겠다.) 이상으로 스프링 프레임워크의 특징에 대하여 대략적으로 정리를 해보았다. Reference위키백과POJO(Plain Old Java Object) 란?Spring 개념 정리","link":"/2020/11/03/spring/%EA%B0%9C%EC%9A%94/"},{"title":"JWT 개요 간단 정리","text":"1. JWT(Json Web Token)란JSON 객체를 사용해서 토큰 자체에 정보들을 저장하고 있는 Web Token 으로 가벼운 인증으로 사용이 쉽다. 일반적으로 클라이언트와 서버, 서비스와 서비스 사이 통신을 할 때 권한 인가(Authorization)을 위해서 사용된다. 2. 구조 Header : Signature를 해싱하기 위한 알고리즘 정보 1234{ &quot;alg&quot; : &quot;HS256&quot;, &quot;typ&quot; : &quot;JWT&quot;} Payload : 서버와 클라이언트가 주고받는, 시스템에서 실제로 사용될 정보에 대한 내용들 1234{ &quot;name&quot; : &quot;jy&quot;, &quot;iat&quot; : 1422779638} Signature : 토큰의 유효성 검증을 위한 문자열로 헤더와 페이로드를 합친 문자열을 서명한 값이다. 헤더의 alg에 정의된 알고리즘과 secret을 이용해 해싱하고 이 값을 다시 base64 인코딩하여 생성한다. 12345HMAC-SHA256( secret, base64urlEncoding(header) + '.' + base64urlEncoding(payload)) 이 세 부분은 각각 Base64 인코딩을 사용하여 점을 사용해서 연결되면 JWT가 완성되며 주로 HTTP 통신 시 Authorization key의 value 로 사용된다. 1234{ //Header Payload Signature &quot;Authorization&quot;: &quot;Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoiankiLCJpYXQiOjE0MjI3Nzk2Mzh9.SNKm-Pcut8DUMBmeQXdIJlM_wFkh4jYd5YtRT369JdI&quot;,} 3. 장점과 단점 장점 중앙의 인증서버, 데이터 스토어에 대한 의존성이 없어서 시스템의 수평확장에 유리하다. Base64 URL Safe Encoding을 사용하여 URL, Cookie, Header 어디에서든 모두 사용 가능하다. 단점 Payload의 정보가 많아지면 네트워크 사용량이 증가하여 데이터 설계 고려 필요 토큰이 클라이언트에 저장되서 서버에서 클라이언트의 토큰을 조작할 수 없다.","link":"/2021/04/23/web/jwt-1/"},{"title":"1.SpringBoot 시작하기","text":"솔루션 회사를 몇년 다니다보니 내가 생각하는 웹서비스 환경의 경험이 적다는 생각이 들어서 A to Z까지 천천히 따라가면서 조금이나마 경험을 늘릴 수 있는 계기가 되지 않을까 싶어서 서적을 하나 구매해보았다. 이하 포스팅할 내용은 모두 스프링 부트와 AWS로 혼자 구현하는 웹 서비스라는 책을 읽고 작성한 내용으로 학습한 내용을 정리하기 위함이다. 개발환경은 책과 좀 다르다. 시간도 지났고 기존에 사용하던 환경이 있으므로 openJDK 11 Gradle 6.7 IntelliJ 유료버전 1. 인텔리제이로 스프링 부트 시작하기이미 인텔리제이는 사용하고 있지만 책에서 언급한 이클립스에 비해 인텔리제이가 가진 장점은 다음과 같다. 강력한 추천 기능(Smart Completion) 훨씬 더 다양한 리팩토링과 디버깅 기능 이클립스의 깃(Git)에 비해 훨씬 높은 자유도 프로젝트 시작할 때 인덱싱을 하여 파일을 비롯한 자원들에 대한 빠른 검색 속도 HTML과 CSS, JS, XML에 대한 강력한 기능 지원 자바, 스프링 부트 버전업에 맞춘 빠른 업데이트 인텔리제이는 무료버전과 유료버전이 모두 존재하지만 커뮤니티(무료) 버전만 사용하더라도 개발에 큰 지장은 없다. 자바 개발에 대한 모든 기능 및 Maven, Gradle과 같은 빌드 도구도 모두 지원한다. 여담으로 둘다 써본 경험에서 불편했던 점은 딱 한가지였는데 임베디드 톰캣이 아닌 외부 톰캣과 연동하는 경우 커뮤니티 버전에선 공식적으로 지원하지 않아서 별도의 플러그인을 설치해서 사용했는데 그게 좀 귀찮았던 기억이 있다. 그리고 이클립스를 쓰다가 인텔리제이로 넘어오면 가장 당황하는 것이 워크스페이스가 없이 프로젝트와 모듈의 개념만 있다는 점이다. 이 말은 인텔리제이는 한번에 하나의 프로젝트만 열린다는 점이다. Gradle로 프로젝트 생성 ArtifactId는 프로젝트의 이름이 된다 그동안 Maven만 사용해봤는데 Gradle이 가진 장점과 단점은 무엇인지 추후에 찾아봐서 포스팅 해봐야겠다. 시간이 지나면서 버전이 바뀐 영향인지 프로젝트 생성부터 책과 약간 다르게 진행이 되긴 하는데 또 그래야 더 찾아보고 공부가 되지 않을까 하는 생각도 들었다. Gradle 프로젝트 생성 완료 Gradle 프로젝트를 springBoot 프로젝트로 변경하기 초기 build.gradle 파일 12345678910111213141516171819plugins { id 'java'}group 'com.springboot.service'version '1.0-SNAPSHOT'repositories { mavenCentral()}dependencies { testImplementation 'org.junit.jupiter:junit-jupiter-api:5.6.0' testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine'}test { useJUnitPlatform()} 음… 여기서부터 책과 벌써 다르다. 아무래도 책의 출판시점에서 2년이나 지났으니 각종 라이브러리, 도구들의 버전업이 일어나면서 여러 내용들이 바뀐듯 하다. 구글링을 해보니 저자분이 [2020.12.16] 기준으로 최신 라이브러리로 버전업한 내용에 대해 정리해놓은 글이 있어서 해당 내용을 참고하였다. 참고링크 : 스프링 부트와 AWS로 혼자 구현하는 웹 서비스 (2020.12.16) 변경된 도구들의 버전은 다음과 같다. 라이브러리,도구명 출판버전 웹버전 Spring Boot 2.1.7 2.4.1 Gradle 4.8~4.10 6.7.1 JUnit 4 5","link":"/2021/04/21/book/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4/1/"},{"title":"3.JPA로 데이터베이스 다루기","text":"3 JPAPosts 클래스는 실제 DB의 테이블과 매칭될 클래스로 Entity 클래스라고 부른다. DB데이터에 작업할 경우 실제 쿼리를 날리기 보단 이 Entity 클래스의 수정을 통해 작업 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.jojoldu.book.springboot.domain.posts;import lombok.Builder;import lombok.Getter;import lombok.NoArgsConstructor;import javax.persistence.*;/*1. @Entity- 테이블과 링크될 클래스- 기본값으로 클래스의 카멜케이스 이름을 언더스코어 네이밍(_)으로 테이블 이름을 매칭한다.- ex) SalesManager.java -&gt; sales_manager table아래 3개는 lombok 어노테이션2. @NoArgsConstructor- 기본생성자 자동추가- public Posts() {} 와 같음3. @Getter- 클래스 내 모든 필드의 Getter 메소드 자동생성4. @Builder- 해당 클래스의 빌더 패턴 클래스를 생성- 생성자 상단에 선언 시 생성자에 포함된 필드만 빌더에 포함*/@Getter@NoArgsConstructor@Entitypublic class Posts { /* 1. @Id - PK 필드 2. @GeneratedValue - PK 생성규칙 - GenerationType.IDENTITY 옵션을 추가해야 auto_increment 된다. */ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; /* 1. @Column - 선언하지 않더라도 해당 클래스의 필드는 모두 컬럼이 된다. - 옵션을 추가할 때만 선언해도 된다. */ @Column(length = 500, nullable = false) private String title; @Column(columnDefinition = &quot;TEXT&quot;, nullable = false) private String content; private String author; @Builder public Posts(String title, String content, String author){ this.title = title; this.content = content; this.author = author; }} Entity 클래스는 Setter 메소드를 만들지 않고 해당 필드의 값 변경이 필요하면 명확히 그 목적과 의도를 나타낼 수 있는 메소드를 추가해야 한다. 12345678public class Order{ public void cancelOrder(){ this.status = false; }}public void 주문서비스의_취소이벤트() { order.cancelOrder();} 기본적인 구조는 생성자를 통해 최종값을 채운 후 DB에 삽입하는 것이고 값 변경이 필요하면 해당 이벤트에 맞는 public 메소드를 호출하여 변경하는 것을 전제로 한다. 생성시점에 값을 넣는 방법으로 생성자와 @Builder를 통해 제공되는 빌더 클래스를 사용할 수 있는데 차이점이 있다면 생성자는 new Example(b,a)처럼 파라미터의 위치를 바꾸더라도 실제 실행 전까지 문제를 찾기 어렵다. 1234public Example(String a, String b){ this.a = a; this.b = b;} 빌더를 사용한다면 어느 필드에 어떤 값을 채워야할 지 명확하게 인지할 수 있다. 1234Example.builder() .a(a) .b(b) .build(); Posts클래스(Entity) 생성이 끝나면 해당 클래스로 Database를 접근하게 해줄 JpaRepository를 생성한다. src/main/java/com/jojoldu/book/springboot/domain/posts/PostsRepository1234import org.springframework.data.jpa.repository.JpaRepository;public interface PostsRepository extends JpaRepository&lt;Posts, Long&gt; {} 보통 ibatis나 MyBatis 등에서 Dao라고 불리는 DB Layer 접근자를 JPA에선 Repository 라고 부르며 인터페이스로 생성한다. 생성 후, JpaRepository&lt;Entity 클래스, PK 타입&gt; 를 상속하면 기본적인 CRUD 메소드가 자동으로 생성된다. @Repositry 어노테이션을 추가할 필요는 없지만 Entity 클래스와 기본 Entity Repository는 함께 위치해야 한다. 생성한 Repository 를 테스트하기 위해 아래 코드를 작성하며 테스트할 기능은 save, findAll 기능이다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.jojoldu.book.springboot.domain.posts;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.Test;import org.junit.jupiter.api.extension.ExtendWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit.jupiter.SpringExtension;import java.util.List;import static org.assertj.core.api.Assertions.assertThat;/*별다른 설정없이 @SpringBootTest를 사용할 경우 H2 데이터베이스를 자동으로 실행한다.*/@ExtendWith(SpringExtension.class)@SpringBootTestpublic class PostsRepositoryTest { @Autowired PostsRepository postsRepository; /* 1. @AfterEach - Junit에서 단위테스트가 끝날 때마다 수행되는 메소드를 지정한다. - 보통은 배포 전 전체 테스트를 수행할 때 테스트간 데이터 침범을 막기 위해 사용된다. - Junit4 -&gt; 5로 넘어가면서 After -&gt; AfterEach 로 변경되었다. */ @AfterEach public void cleanup() { postsRepository.deleteAll(); } @Test public void 게시글저장_불러오기() { //given String title = &quot;테스트 게시글&quot;; String content = &quot;테스트 본문&quot;; /* 2. postsRepository.save - 테이블 posts에 insert/update 쿼리를 실행한다. - id값이 있으면 update, 없다면 insert 쿼리가 실행된다. */ postsRepository.save(Posts.builder() .title(title) .content(content) .author(&quot;jojoldu@gmail.com&quot;) .build()); /* 3. postsRepository.findAll - 테이블 posts에 있는 모든 데이터를 조회해오는 메소드 */ //when List&lt;Posts&gt; postsList = postsRepository.findAll(); //then Posts posts = postsList.get(0); assertThat(posts.getTitle()).isEqualTo(title); assertThat(posts.getContent()).isEqualTo(content); }} 3.4 등록/수정/조회 API 만들기API를 만들기 위해 총 3개의 클래스가 필요하다. Request 데이터를 받을 Dto API 요청을 받을 Controller 트랜잭션, 도메인 기능 간의 순서를 보장하는 Service 여기서 Service는 비지니스 로직을 처리하는 것이 아니라 트랜잭션, 도메인 간 순서 보장의 역할만 한다. Web, Service, Repository, Dto, Domain 이 5가지 레이어에서 비지니스 처리를 담당해야 할 곳은 **Domain**이다. 기존에 서비스로 처리하던 방식을 트랜잭션 스크립트라고 한다. 1234567891011121314151617181920212223242526@Transactionalpublic Order cancelOrder(int orderId){ //1) 데이터베이스로부터 주문정보, 결제정보, 배송정보 조회 OrdersDto order = ordersDao.selectOrders(orderId); BillingDto billing = billingDao.selectBilling(orderId); DeliveryDto delivery = deliveryDao.selectDelivery(orderId); //2) 배송 취소를 해야하는지 상태값 확인 String deliveryStatus = delivery.getStatus(); //3) 만약 배송중이라면 배송취소로 변경 if(&quot;IN_PROGRESS&quot;.equals(deliveryStatus)){ delivery.setStatus(&quot;CANCEL&quot;); deliveryDao.update(delivery); } //4) 각 테이블에 취소 상태 Update order.setStatus(&quot;CANCEL&quot;); orderDao.update(order); billing.setStatus(&quot;CANCEL&quot;); deliveryDao.update(billing); return order;} 모든 로직이 서비스 클래스 내부에서 처리된다면 서비스 계층이 무의미하며, 객체란 단순히 데이터 덩어리 역할만 하게 된다. 반면 도메인 모델에서 처리할 경우 아래와 같은 코드가 될 수 있다. 1234567891011121314151617@TransactionalPublic Order cancelOrder(int orderId){ //1) OrdersDto order = ordersDao.selectOrders(orderId); BillingDto billing = billingDao.selectBilling(orderId); DeliveryDto delivery = deliveryDao.selectDelivery(orderId); //2-3) delivery.cancel(); //4) order.cancel(); billing.cancel(); return order;} order, billing, delivery가 각자 본인의 취소 이벤트 처리를 하며, 서비스 메소드는 트랜잭션과 도메인 간의 순서만 보장해 준다. 스프링에서 Bean을 주입하는 방식은 다음과 같다. @Autowired setter 생성자 가장 권장하는 방식은 생성자로 주입받는 방식이며 @Autowired는 권장하지 않는다. 아래 Service 코드에서 생성자는 직접 쓰지 않고 @RequiredArgsConstructor어노테이션에서 해결해 준다. final이 선언된 모든 필드를 인자값으로 하는 생성자를 롬북에서 대신 생성해준다. 이처럼 어노테이션을 사용하는 이유는 해당 클래스의 의존성 관계가 변경될 때마다 생성자 코드를 변경하는 수고를 덜기 위함이다. 1234567891011121314151617import com.jojoldu.book.springboot.domain.posts.PostsRepository;import com.jojoldu.book.springboot.web.dto.PostsSaveRequestDto;import lombok.RequiredArgsConstructor;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;@RequiredArgsConstructor@Servicepublic class PostsService { private final PostsRepository postsRepository; @Transactional public Long save(PostsSaveRequestDto requestDto) { return postsRepository.save(requestDto.toEntity()).getId(); }} Controller와 Service에서 사용할 Dto 클래스는 언듯 Entity 클래스와 유사한 형태지만 추가로 생성해야한다. 즉, 절대로 Entity 클래스를 Request/Response 클래스로 사용해선 안된다. 이유는 Entity 클래스는 데이터베이스와 맞닿은 핵심 클래스로 화면 변경은 사소한 변경인데 이를 건들기 위해 테이블과 연결된 Entity 클래스를 변경하는 것은 너무 큰 변경이다. 수많은 서비스 클래스나 비즈니스 로직들이 Entity 클래스를 기준으로 동작하며 Entity 클래스가 변경되면 여러 클래스에 영향을 끼지지만 Request/Response 용 Dto는 View를 위한 클래스라 자주 변경이 필요하다. 이처럼 View Layer 와 DB Layer 의 역할을 철저히 분리하는게 좋다. 예를 들어 Controller에서 결과값으로 여러 테이블을 조인해야 하는 경우 Entity 클래스만으로 표현하기 어려운 경우도 있다. 다음은 JPA를 사용한 게시판의 등록 API 테스트 코드이다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.jojoldu.book.springboot.web;import com.jojoldu.book.springboot.domain.posts.Posts;import com.jojoldu.book.springboot.domain.posts.PostsRepository;import com.jojoldu.book.springboot.web.dto.PostsSaveRequestDto;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.Test;import org.junit.jupiter.api.extension.ExtendWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.boot.test.web.client.TestRestTemplate;import org.springframework.boot.web.server.LocalServerPort;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.test.context.junit.jupiter.SpringExtension;import java.util.List;import static org.assertj.core.api.Assertions.assertThat;@ExtendWith(SpringExtension.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class PostsApiControllerTest { @LocalServerPort private int port; @Autowired private TestRestTemplate restTemplate; @Autowired private PostsRepository postsRepository; @AfterEach public void tearDown() throws Exception { postsRepository.deleteAll(); } @Test public void Posts_등록된다() throws Exception { //given String title = &quot;title&quot;; String content = &quot;content&quot;; PostsSaveRequestDto requestDto = PostsSaveRequestDto.builder().title(title).content(content).author(&quot;author&quot;).build(); String url = &quot;http://localhost:&quot; + port + &quot;/api/v1/posts&quot;; //when ResponseEntity&lt;Long&gt; responseEntity = restTemplate.postForEntity(url, requestDto, Long.class); //then assertThat(responseEntity.getStatusCode()).isEqualTo(HttpStatus.OK); assertThat(responseEntity.getBody()).isGreaterThan(0L); List&lt;Posts&gt; all = postsRepository.findAll(); assertThat(all.get(0).getTitle()).isEqualTo(title); assertThat(all.get(0).getContent()).isEqualTo(content); }} HelloController와 달리 @WebMvcTest를 사용하지 않는데 @WebMvcTest의 경우 JPA기능이 작동하지 않기 때문인데 Controller와 ControllerAdvice 등 외부 연동과 관련된 부분만 활성화되니 지금 처럼 JPA 기능까지 한번에 테스트할 때는 @SpringBootTest 와 TestRestTemplate을 사용하면 된다. JPA를 사용할 때 update 기능에서 데이터베이스에 쿼리를 날리는 부분이 없다.이게 가능한 이유는 JPA의 영속성 컨텍스트 때문이다. 영속성 컨텍스트란, 엔티티를 영구 저장하는 환경으로 일종의 논리적 개념이라고 보면 되며 JPA의 핵심 내용은 엔티티가 영속성 컨텍스트에 포함되어 있냐 아니냐로 갈린다. JPA의 엔티티 매니저가 활성화된 상태로(Spring Data Jpa를 쓴다면 기본 옵션) 트랜잭션 안에서 데이터베이스에서 데이터를 가져오면 이 데이터는 영속성 컨텍스트가 유지된 상태이다. 이 상태에서 해당 데이터의 값을 변경하면 트랜잭션이 끝나는 시점에 해당 테이블에 변경분을 반영한다. 즉, Entity 객체의 값만 변경하면 별도로 Update쿼리를 날릴 필요가 없는데 이를 더티 체킹(dirty checking)이라고 한다. 3.5 JPA Auditing으로 생성시간/수정시간 자동화하기보통 엔티티에는 해당 데이터의 생성시간과 수정시간을 포함하는데 반복적인 코드를 모든 테이블과 서비스 메소드에 포함하면 너무 귀찮으니 JPA Auditing를 사용해보자. LocalDate 사용Java8부터 LocalDate와 LocalDateTime이 등장하여 그간 Java의 기본 날짜 타입인 Date의 문제점을 제대로 고쳤으니 꼭 사용하자. BaseTimeEntity.java123456789101112131415161718192021import lombok.Getter;import org.springframework.data.annotation.CreatedDate;import org.springframework.data.annotation.LastModifiedDate;import org.springframework.data.jpa.domain.support.AuditingEntityListener;import javax.persistence.EntityListeners;import javax.persistence.MappedSuperclass;import java.time.LocalDateTime;@Getter@MappedSuperclass@EntityListeners(AuditingEntityListener.class)public abstract class BaseTimeEntity { @CreatedDate private LocalDateTime createDate; @LastModifiedDate private LocalDateTime modifiedDate;} BaseTimeEntity클래스는 모든 Entity의 상위 클래스가 되어 Entity들의 createdDate, modifiedDate를 자동으로 관리하는 역할이다. @MappedSuperclass JPA Entity 클래스들이 BaseTimeEntity을 상속할 경우 필드들(createdDate, modifiedDate)도 컬럼으로 인식하도록 한다. @EntityListeners(AuditingEntityListener.class) BaseTimeEntity 클래스에 Auditing 기능을 포함시킨다. CreatedDate Entity가 생성되어 저장될 때 시간이 자동 저장된다. LastModifiedDate 조회한 Entity의 값을 변경할 때 시간이 자동 저장된다. 이후 앞서 만든 Posts 클래스가 BaseTimeEntity를 상속받도록 변경한다. 1234 ...public class Posts extends BaseTimeEntity { ...} 마지막으로 JPA Auditing 어노테이션들을 모두 활성화할 수 있도록 Application 클래스에 활성화 어노테이션을 추가한다. 12345678@EnableJpaAuditing // JPA Auditing 활성화@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }}","link":"/2021/04/22/book/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4/3/"},{"title":"2.테스트코드 작성하기","text":"JUnit4 -&gt; 5 변경점 12345678910111213141516171819202122232425262728293031323334353637383940414243junit4 -&gt; 5 1. @Test 패키지 위치 변경org.junit.Test-&gt; org.junit.jupiter.api.Test 2. @RunWith Junit5에서 @ExtendWith 로 변경되서 어노테이션명과 패키지위치 변경org.junit.runner.RunWith-&gt; org.junit.jupiter.api.extension.ExtendWith@RunWith-&gt; @ExtendWith 3. SpringRunner SpringExtension 으로 변경되서 클래스명과 패키지위치 변경SpringRunner-&gt; SpringExtensionorg.springframework.test.context.junit4.SpringRunner-&gt; org.springframework.test.context.junit.jupiter.SpringExtension 4. @After 테스트 메소드가 끝날때마다 수행되는 @After 도 Junit5에서 @AfterEach 로 변경되었기 때문에 어노테이션과 패키지위치 변경@After-&gt; @AfterEachorg.junit.After-&gt; org.junit.jupiter.api.AfterEach 5. @Before 마찬가지로 @BeforeEach 로 변경되서 어노테이션과 패키지위치 변경@Before-&gt; @BeforeEachorg.junit.Before-&gt; org.junit.jupiter.api.BeforeEach 샘플 컨트롤러 코드 12345678910111213141516package com.jojoldu.book.springboot.web;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;//컨트롤러를 JSON을 반환하는 컨트롤러로 만들어준다.@RestControllerpublic class HelloController { //HTTP Method인 Get의 요청을 받을 수 있는 API를 만들어 준다. @GetMapping(&quot;/hello&quot;) public String hello() { return &quot;hello&quot;; }} 샘플 단위 테스트 코드 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.jojoldu.book.springboot.web;import org.junit.jupiter.api.Test;import org.junit.jupiter.api.extension.ExtendWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;import org.springframework.test.context.junit.jupiter.SpringExtension;import org.springframework.test.web.servlet.MockMvc;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;/*1. @ExtendWith(SpringExtension.class)- 테스트를 진행할 때 JUnit에 내장된 실행자 외에 다른 실행자를 실행시킨다.- 여기서는 SpringExtension 이라는 스프링 실행자를 사용한다.- 스프링 부트 테스트와 JUnit 사이에 연결자 역할- JUnit4 -&gt; 5로 넘어오면서 사용하는 어노테이션과 클래스가 각각 @RunWith -&gt; @ExtendWith 로 SpringRunner -&gt; SpringExtension 으로 변경되었다.2. @WebMvcTest- 여러 스프링 테스트 어노테이션 중, Web(Spring MVC)에 집중할 수 있는 어노테이션- 선언할 경우 @Controller, @ControllerAdvice 등을 사용할 수 있다.- 단, @Service, @Component, @Repository 등은 사용할 수 없다.*/@ExtendWith(SpringExtension.class)//1@WebMvcTest(controllers = HelloController.class)//2public class HelloControllerTest { /* 3. AutoWired - 스프링이 관리하는 빈(Bean)을 주입 받는다. 4. private MockMvc mvc - 웹 API를 테스트할 때 사용한다. - 스프링 MVC 테스트의 시작점 - 이 클래스를 통해 HTTP GET, POST 등에 대한 API 테스트를 할 수 있다. */ @Autowired//3 private MockMvc mvc;//4 @Test public void hello가_리턴된다() throws Exception { String hello = &quot;hello&quot;; /* 5. mvc.perform(get(&quot;/hello&quot;)) - MockMvc를 통해 /hello 주소로 HTTP GET 요청을 한다. - 체이닝이 지원되어 아래와 같이 여러 검증 기능을 이어서 선언할 수 있다. 6. .andExpect(status().isOk()) - mvc.perform의 결과를 검증한다. - HTTP Header의 Status를 검증한다. - 우리가 흔히 알고 있는 200, 404, 500 emddml 상태를 검증한다. - 여기선 OK 즉, 200인지 아닌지를 검증한다. 7. .andExpect(content().string(hello)) - mvc.perform의 결과를 검증한다. - 응답 본문의 내용을 검증한다. - Controller에서 &quot;hello&quot;를 리턴하기 때문에 이 값이 맞는지 검증한다. */ mvc.perform(get(&quot;/hello&quot;))//5 .andExpect(status().isOk())//6 .andExpect(content().string(hello));//7 }} 2.3 롬북(Lombok)자바 개발 시 자주 사용하는 코드 Getteer, Setter, 기본생성자, toString 등을 어노테이션으로 자동 생성해준다. 1234dependencies { // lombok implementation('org.projectlombok:lombok')}","link":"/2021/04/21/book/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4/2/"},{"title":"4.머스테치로 화면 구성하기","text":"4. 머스테치로 화면 구성하기4.1 서버 템플릿 엔진템플릿 엔진이란, 지정된 템플릿 양식과 데이터가 합쳐져 HTML문서를 출력하는 소프트웨어를 이야기한다. 서버 템플릿 엔진을 이용한 화면 생성은 서버에서 Java 코드로 문자열을 만든 뒤 이 문자열을 HTML로 변환하여 브라우저로 전달한다. 반면 클라이언트 템플릿 엔진(Vue, React 등)을 이용한 SPA(Single Page Application)은 브라우저에서 화면을 생성한다. 즉, 서버에서 이미 코드가 벗어난 경우라서 서버에서는 Json 혹은 Xml 형식의 데이터만 전달하고 클라이언트에서 조립한다. 최근엔 리액트나 뷰와 같은 자바스크립트 프레임워크에서 서버사이드렌더링을 지원하는 모습을 볼 수 있지만 그건 나중에 생각하자. 머스테치머스테치는 많은 언어를 지원하는 심플한 템플릿 엔진이다. 스프링 부트에서 공식 지원하는 템플릿 엔진으로 gradle에 의존성 한줄 추가하면 바로 사용할 수 있다. 파일위치는 기본적으로 src/main/resources/templates이며 이 위치에 머스테치 파일을 두면 스프링 부트에서 자동으로 로딩한다. 해당 위치에 index.mustache를 생성한 후 이 머스테치에 URL을 매핑하는데 이는 Controller에서 진행한다. IndexController 12345678910111213import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;@Controllerpublic class IndexController { @GetMapping(&quot;/&quot;) public String index() { return &quot;index&quot;; }} 머스테치 스타터 의존성을 추가했기 때문에 컨트롤러에서 문자열을 반환할 때 앞의 경로와 뒤의 파일 확장자는 자동으로 지정된다. 즉, 여기선 “index”를 반환하므로 src/main/resources/templates/index.mustache로 전환되어 View Resolver가 처리하게 된다. (View Resolver는 URL 요청의 결과를 전달할 타입과 값을 지정하는 관리자 격으로 볼 수 있다.) 화면 구성 시 bootstrap을 사용하는데 공통된 부분에 대해선 layout을 따로 둬서 header와 footer 파일을 각각 만들어서 공통된 코드는 해당 위치에 생성한다. 여기서 페이지 로딩속도를 높이기 위해 css는 header에, js는 footer에 두는데 HTML은 위에서부터 코드가 실행되기 때문에 head가 다 실행되고서야 body가 실행된다. 즉, head가 다 불러지지 않으면 사용자 쪽에선 백지 화면만 노출되며 특히 js의 용량이 크면 클수록 body 부분의 실행이 늦어지기 때문에 js는 body 하단에 두어 화면이 다 그려진 뒤에 호출하는 것이 좋다. header와 footer를 index에 추가하는건 아래와 같다. 12345678910{{&gt;layout/header}}&lt;h1&gt;스프링 부트로 시작하는 웹 서비스&lt;/h1&gt;&lt;div class=&quot;col-md-12&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-6&quot;&gt; &lt;a href=&quot;/posts/save&quot; role=&quot;button&quot; clas=&quot;btn btn-primary&quot;&gt;글 등록&lt;/a&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;{{&gt;layout/footer}} {{> }} 는 현재 머스테치 파일을 기준으로 다른 파일을 가져온다. 화면의 버튼에 API를 호출하는 js파일을 작성하여 footer.mustache에 추가한다. 1234567&lt;script src=&quot;https://code.jquery.com/jquery-3.3.1.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js&quot;&gt;&lt;/script&gt;&lt;!--index.js 추가--&gt;&lt;script src=&quot;/js/app/index.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; index.js 호출 코드는 절대경로(/)로 바로 시작하는데 스프링 부트는 기본적으로 src/main/resources/static에 위치한 자바스크립트, CSS, 이미지 등 정적 파일들은 URL에서 / 로 설정된다. PostsRepository 인터페이스 123456public interface PostsRepository extends JpaRepository&lt;Posts, Long&gt; { @Query(&quot;SELECT p FROM Posts p ORDER BY p.id DESC&quot;) List&lt;Posts&gt; findAllDesc();} @Query 어노테이션을 사용하면 SpringDataJpa에서 제공하지 않는 메소드를 쿼리로 직접 작성할 수 있다. 보통 규모가 있는 프로젝트에선 데이터 조회는 FK의 조인, 복잡한 조건 등으로 인해 Entity 클래스만으로 처리가 어려워 조회용 프레임워크를 추가로 사용한다. 대표적 예로 querydsl, jooq, MyBatis 등이 있는데 해당 프레임워크 중 하나로 조회를 하고 그 외 등록/수정/삭제 등은 SpringDataJpa를 통해 진행한다. PostsService 123456... @Transactional(readOnly = true) public List&lt;PostsListResponseDto&gt; findAllDesc() { return postsRepository.findAllDesc().stream().map(PostsListResponseDto::new).collect(Collectors.toList()); }... @Transactional 어노테이션에 추가된 readOnly 옵션을 true로 주면 트랜잭션 범위는 유지하되, 조회기능만 남겨두어 조회 속도가 개선되기 때문에 등록, 수정, 삭제 기능이 전혀 없는 서비스 메소드에서 사용하는 것을 추천한다. IndexController 123456789101112@RequiredArgsConstructor@Controllerpublic class IndexController { private final PostsService postsService; @GetMapping(&quot;/&quot;) public String index(Model model) { model.addAttribute(&quot;posts&quot;, postsService.findAllDesc()); return &quot;index&quot;; }} Model 서버 템플릿 엔진에서 사용할 수 있는 객체를 저장할 수 있다. 여기서는 postsService.findAllDesc()로 가져온 결과를 posts로 index.mustache에 전달한다. REST에서 CURD는 다음과 같이 HTTP Method에 매핑된다. 생성(Create) : POST 읽기(Read) : GET 수정(Update) : PUT 삭제(Delete) : DELETE","link":"/2021/04/22/book/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4/4/"},{"title":"5.중간메모","text":"복습 겸 다시 프로젝트 생성해서 만들어보다가 몇가지 간략히 정리 1. springboot에서 html파일을 templates에서 읽도록 하기템플릿 엔진과 관련된 의존성을 추가하면 자동으로 /recourses/templates 아래에서 템플릿 파일을 찾도록 하는거 같은데 원래 기본 경로는 /recourses/static 이다. 따라서 별다른 설정을 하지 않고 html 파일을 templates 폴더 밑에 놓고 찾으려고 하면 당연히 404 에러를 볼수 밖에 없다. html 파일을 templates 아래에 관리하고 싶다면 몇가지 작업을 해야하는데 우선 스프링부트에서 WebMVC 설정을 유지하면서 기능을 확장하기 위해 WebMvcConfigurer를 implements 하고 addResourceHandlers 를 오버라이드하여 아래와 같이 작성한다. 123456789101112@RequiredArgsConstructor@Configurationpublic class WebConfig implements WebMvcConfigurer { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(&quot;/**&quot;) .addResourceLocations(&quot;classpath:/templates/&quot;) .setCacheControl(CacheControl.maxAge(10, TimeUnit.MINUTES)); }} 2. application.properties -&gt; application.yml 변환가독성 측면에서 yaml 파일이 더 좋아보여서 기존 내용을 변환해서 쓰려다보니 naver oauth2 설정을 하면 오류가 발생한다. redirect-uri: '{baseUrl}/{action}/oauth2/code/{registrationId}' yaml 에서는 / (슬러시)를 그대로 쓰면 파싱 에러가 난다. 따옴표나 작은 따옴표로 감싸주면 된다.","link":"/2021/04/25/book/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4/5/"},{"title":"3. 스트림의 새로운 표준 - 리액티브 스트림","text":"API 불일치 문제CompletableStage를 이용하는 자바 코어 라이브러리와 RxJava 같은 다양한 라이브러리가 있어서, 코드를 작성할 때 다양한 선택을 할 수 있지만 과도하게 많은 선택지는 시스템을 지나치게 복잡하게 만들 수 있다. 핵심적인 문제는 라이브러리 공급자가 일관된 API를 만들어낼 수 있는 표준화된 방법이 없다는 사실이다. 풀 방식과 푸시 방식리액티브 초기 단계에서 모든 라이브러리의 데이터 흐름은 소스에서 구독자에게 푸시되는 방식이었다. 풀 방식으로 요소를 하나씩 요청할 경우 비동기 논블로킹 방식을 사용하더라도 각 요소에 대한 요청을 처리 하면서 대기시간이 발생하여 전체 처리시간 중 많은 시간을 유휴 상태로 있게 된다. 푸시 방식을 도입하면서 요청하는 횟수를 최소화하여 전체 처리 시간을 최적화할 수 있었다. 하지만 푸시 모델만 사용하는 것은 기술적 한계가 있는데 메시지 기반 통신의 본질은 요청에 응답하는 것인데 프로듀서가 컨슈머의 처리 능력을 무시하면 전반적인 시스템 안정성에 영향을 미칠 수 있기 때문이다. 흐름제어 느린 프로듀서와 빠른 컨슈머 순수한 푸시 모델은 동적으로 시스템의 처리량을 증가시키는 것이 불가능하다. 빠른 프로듀서와 느린 컨슈머 프로듀서는 컨슈머가 처리할 수 있는 것보다 더 많은 데이터를 전송할 수 있으며 이로 인해 부하를 받는 컴포넌트에 치명적인 오류가 발생할 수 있다. 이를 해결하기 위한 직관적인 방법은 큐에 수집하는 것인데 3가지 유형으로 구분할 수 있다. 무제한 큐: 메모리 한도에 도달하면 전체 시스템이 손상될 가능성이 있다.(복원력이 떨어짐) 크기가 제한된 드롭 큐: 메시지의 중요성이 낮을 때 사용되는 방법으로 큐가 가득 차면 메시지를 무시하는데 중요한건 데이터 세트가 변경된다는 점이다. 크기가 제한된 블로킹 큐: 가장 느린 컨슈머의 처리량에 의해 시스템의 전체 처리량이 제한된다. 시스템의 비동기 동작을 모두 무효화하여 절대 받아들일 수 없는 시나리오다. 이런 시스템 부하에 적절하게 대응하는 방법으로 배압 제어 메커니즘이 있다. 리액티브 스트림의 기본 스펙리액티브 스트림 스펙에는 Publisher, Subscriber, Subscription, Processor의 네 가지 기본 인터페이스가 정의돼 있다. Publisher : Observable과 비교하면 Publisher와 Subscriber를 연결하기 위한 표준화된 진입점을 의미 Subscriber : Observer와 비슷한데 onSubscribe라는 추가 메서드를 제공하는데 Subscriber에게 구독이 성공했음을 알리는 API 메서드 Subscription : 원소 생성을 제어하기 위해 기본적인 사항을 제공 cancel() : 스트림에서 구독을 취소하거나 발행을 완전히 취소 가능 request(long n) : 요청하는 Publisher가 보내줘야 하는 데이터 크기를 알려줄 수 있음 ▶️ Publisher에서 유입되는 원소의 개수가 처리할 수 있는 제한을 초과하지 않을 것을 확신할 수 있다. 리액티브 스트림은 순수 푸시 모델과는 달리 배압을 적절하게 제어할 수 있는 하이브리드 푸시-풀 모델을 제공한다. 순수 푸시 모델을 사용하고 싶으면 최대 개수 요청 request(Long.MAX_VALUE) 순수 풀 모델을 사용하고 싶으면 onNext()가 호출될 때마다 요청 Processor : Publisher와 Subscriber의 혼합 형태로 Publisher와 Subscriber 사이에 몇가지 처리 단계를 추가하도록 설계됐다. 12public interface Processor&lt;T, R&gt; extends Subscriber&lt;T&gt;, Publisher&lt;R&gt; {} 리액티브 스트림 기술 호환성 키트(TCK)모든 동작을 검증하고 반응 라이브러리를 표준화하여 서로 호환하는지 확인하는 공통 도구로 모든 리액티브 스트림 코드를 방어하고 지정된 규칙에 따라 구현을 테스트 한다. TCK github : https://github.com/reactive-streams/reactive-streams-jvm/tree/master/tck 리액티브 스트림을 활용한 비동기 및 병렬 리액티브 스트림 API는 Publisher가 생성하고 Subscriber가 소비한 모든 신호는 처리 중에 논블로킹이어야 하며 방해받지 않아야 한다고 규칙에 명시되어 있다. 모든 프로세서나 코어를 효율적으로 사용하려면 병렬처리가 필요하고 이는 일반적으로 onNext 메서드를 병렬로 호출하는 것을 뜻하지만 on*** 메서드의 호출은 스레드 안전성을 보장하는 방식으로 신호를 보내야 하며 다중 스레드에서 수행되는 경우 외부적인 동기화를 사용해야 한다. 즉, 스트림의 요소를 병렬 처리할 수 없다. 자원을 효율적으로 활용하기 위해 스트림 처리 파이프의 각 단계에 메시지를 비동기적으로 전달하는 것이다. 상황에 따라서 처리단계를 각각 별도의 스레드로 처리하고 각 스레드 사이에 큐와 같은 데이터 구조를 적용하여 메시지를 독립적으로 제공하고 사용하도록 할수 있다.","link":"/2021/11/28/book/%EC%8B%A4%EC%A0%84-%EC%8A%A4%ED%94%84%EB%A7%815%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/3/"},{"title":"2. 스프링을 이용한 리액티브 프로그래밍 - 기본 개념","text":"관찰자(Observer) 패턴 이벤트를 발생시키는 역할(주체Subject), 이벤트를 수신하는 역할(객체, 즉 관찰자Observer)의 두가지 핵심 요소가 존재 Observer는 Subject에 등록되고 Subject로부터 알림을 수신 Java의 내장 클래스인 Observable, Observer는 java9 부터 deprecated 되었다. interface가 아니라 class로 구현되어 있어서 이미 다른 클래스를 상속받은 클래스가 Observable을 상속할 수 없어서 재사용성에 제약이 생긴다. Observable의 핵심 메소드 중 하나인 setChanged() 메소드가 protected로 정의되어 있어서 사용하려면 상속받은 서브클래스만 해당 메소드를 호출할 수 있다. Observable의 알림은 순서를 보장할 수 없고 상태 변경 역시 1:1로 일치하지 않아서 멀티 스레드 환경에서 thread-safe 하지 않다. Serializable을 구현하지 않기 때문에 Observable을 상속받은 서브클래스도 직렬화할 수 없다. 발행-구독 패턴스프링 프레임워크는 이벤트처리를 위해 @EventListener어노테이션과 이벤트 발행을 위한 ApplicationEventPublisher클래스를 제공한다. 관찰자 패턴과의 차이점은 게시자와 구독자 사이에 간접적인 이벤트 채널(=메시지 브로커 or 이벤트 버스)을 제공하여 구독자는 이벤트 채널은 알고 있지만 게시자가 누구인지는 신경쓰지 않는다. SseEmitter를 사용하면 스프링 프레임워크를 브로커를 사용하여 발행-구독 패턴을 구현할 수 있다.다만 로직을 구현함에 있어 스프링의 내부 메커니즘을 사용했고 이는 프레임워크의 변경으로 인해 프로그램의 안정성을 보장할 수 없는 단점이 있다. 리액티브 프레임워크 RxJava자바 플랫폼에서 리액티브 프로그래밍을 위한 표준 라이브러리는 RxJava 1.x 였고 현재(2021 기준)는 2.x를 지나 3.x까지 출시되었다. RxJava 라이브러리는 **Reactive Extensions(혹은 ReactiveX)**의 자바 구현체로 종종 관찰자 패턴, 반복자 패턴 및 함수형 프로그래밍의 조합으로 정의된다. RxJava의 기본적인 Observer 인터페이스는 아래와 같이 설계할 수 있다. 12345public interface RxObserver&lt;T&gt; { void onNext(T next); void onComplete(); void onError(Exception e);} RxJava에서 아래와 같이 주기적으로 비동기 이벤트 시퀀스를 생성할 경우 이벤트가 생성되는 것과 별개의 스레드에서 사용되기 때문에 메인 스레드가 종료되지 않도록 sleep()을 쓰거나 다른방법으로 종료를 지연시킬 수 있다. 123Observable.interval(1, TimeUnit.SECONDS) .subscribe(e -&gt; System.out.println(&quot;Received: &quot; +e)); Thread.sleep(5000); 마블 다이어그램RxJava는 연산자를 통해 스트림의 원소를 조정하거나 구조 자체를 변경할 수 있다. 연산자가 복잡한 변환을 수행할 경우 이를 시각적으로 표현하여 그 동작을 효과적으로 설명하기 위한 목적으로 마블 다이어그램(marble diagram)이 발명됐다. 위아래 실선(ㅡ&gt;) : Observable의 시간흐름(Timeline)을 의미한다. 각 도형(○,□) : Observable에서 발행하는 데이터로 발행될때마다 onNext 메서드가 호출된다. 파이프(|) : 데이터 발행을 모두 완료했다는 의미로 onCompleted 메서드가 호출된다. 위에서 아래로 점선(—&gt;) : 함수의 입력,출력을 의미한다. 가운데 박스 : 함수를 의미하며 입력된 값에 어떤 변환작업을 하는지 나타내고 있다. 엑스(X) : 함수에서 입력된 값을 처리하는 중 에러가 발생하거나 비정상적으로 종료되었음을 의미하며 onError 메서드가 호출된다. RxJava와 관련된 모든 연산자는 이러한 마블다이어그램으로 표현되고 있으니 익숙해질 필요가 있다.","link":"/2021/11/28/book/%EC%8B%A4%EC%A0%84-%EC%8A%A4%ED%94%84%EB%A7%815%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/2/"},{"title":"1. 왜 리액티브 스프링인가?","text":"리액티브(반응형)이 필요한 이유 증가하는 요청, 부하에 대해서 높은 응답성을 유지해야 한다. 메시지 기반 통신을 바탕으로 탄력성과 복원력을 확보하하여 높은 응답성을 추구한다. 탄력성 자원을 비례적으로 추가하거나 제거하여 시스템의 처리량의 자동으로 증감 하는 것 복원력 시스템의 실패에도 반응성을 유지하는 것 시스템의 기능 요소를 격리해 모든 내부 장애를 격리하고 독립성을 확보함으로써 달성 메시지 기반 통신(Message-driven) 제한된 리소스의 활용도를 높이기 위해서 비동기 논블로킹 모델을 사용해야 한다. 메시지 브로커를 사용하면 대기열을 모니터링하여 시스템의 부하관리 및 탄력성을 제어할 수 있다. 리액티브 선언문(https://www.reactivemanifesto.org/ko/glossary)","link":"/2021/11/28/book/%EC%8B%A4%EC%A0%84-%EC%8A%A4%ED%94%84%EB%A7%815%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/1/"},{"title":"4-2. 리액터 프로젝트 심화학습","text":"리액티브 스트림의 수명 주기조립(assembling) 단계 처리 흐름에서 사용하는 연산자를 조합한 빌더 API처럼 보이지만 일반적인 빌더 패턴과 달리 리액터 API는 불변성(Immutability)을 제공한다.(적용된 각각의 연산자가 새로운 객체를 생성한다.) 스트림 구성을 조작하고 더나은 스트림 전달을 위한 다양한 기술을 적용할 수 있는 단계 구독 단계 특정 Publisher를 구독할 때 발생 조립 단계에서 일련의 Publisher 체인이 연결되었고 최상위 래퍼를 구독하면 해당 체인에 대한 구독 프로세스가 시작된다. 조립단계와 동일한 최적화를 수행할 수 있다. 리액터에서 멀티 스레딩을 지원하는 일부 연산자는 구독이 발생하는 작업자를 변경할 수 있다. 런타임 단계 게시자와 구독자 간에 실제 신호가 교환되는 단계 교환하는 처음 두 신호는 onSubscribe, request onSubscribe 메서드는 최상위 소스에서 호출 구독이 모든 구독자 체인을 통과하여 마지막 구독자가 구독 체인에 대한 정보를 수신하고 메시지 수신을 시작하려면 Subscription#request 메서드를 호출해 전송을 시작해야 한다. 런타임 중에도 request를 줄이기 위한 최적화를 적용할 수 있다. 리액터에서 스레드 스케줄링 모델멀티스레딩 실행을 위해 제공하는 연산자 사이의 차이점에 대해서 확인 다른 워커로 실행을 전환할 수 있는 네 가지 연산자 publishOn 연산자 런타임 실행의 일부를 지정된 워커로 이동 Scheduler 인터페이스를 사용하여 현재 스트림에 대한 특정 워커를 선택할 수 있다. 내부적으로 전용 워커가 메시지를 하나씩 처리할 수 있도록 새로운 원소를 제공하는 큐를 가지고 있다. 리액티브 스트림의 모든 원소는 하나씩(동시에는 아니지만) 처리되므로 항상 모든 이벤트에 순서를 엄격하게 정의할 수 있다.(이 속성을 **직렬성(serializability)**라고 한다.) 병렬 처리를 할 수 없다는 말처럼 들리지만 병렬 처리도 가능한데 예를 들어 처리 단계 사이에 비동기 영역을 추가해서 독립적으로 작업해 비동기 처리를 할 수 있다. subscribeOn 연산자 구독체인에서 워커의 작업 위치를 변경 보통 호출 시점에서 상위 스트림에 해당하는 부분의 스레드를 설정 parallel 연산자 하위 스트림에 대한 플로 분할과 분할된 플로 간 균형 조정 역할123456Flux.range(0, 10000) .parallel() .runOn(Schedulers.parallel()) .map() .filter() .subscribe() parallel연산자를 사용하면 ParallelFlux를 동작시킨다. 다수의 Flux를 추상화하여 Flux간에 데이터의 크기 균형을 이룬다. Scheduler Scheduler.schedule : Runnable 작업을 예약가능 Scheduler.createWorker : 동일한 방법으로 Runnable 작업 예약이 가능한 Worker 인터페이스의 인스턴스를 제공 Scheduler인터페이스 / Workder인터페이스의 차이점 : 워커 풀 / Thread 또는 리소스를 추상화한 것 리액터에서 제공하는 스케줄러 인터페이스의 3가지 주요 구현체 SingleScheduler : 모든 작업을 한 개의 전용 워커에 예약가능, 시간에 의존적 ParallelScheduler : 고정된 크기의 작업자 풀에서 작동(CPU 코어 수로 기본크기 제한) ElasticScheduler : 동적으로 작업자를 만들고 스레드 풀을 캐시, 생성된 스레드 풀의 최대 개수는 제한되지 않음 리액터 컨텍스트 Context는 스트림을 따라 전달되는 인터페이스 런타임 단계에서 필요한 컨텍스트 정보에 엑세스할 수 있도록 하는 것 멀티스레드 환경의 비동기 처리방식에서 ThreadLocal가 가지는 한계를 해결할 수 있다. 변수에 데이터를 넣은 후 publishOn 등을 통해 다른 워커에서 작업 플로를 수행하면 데이터를 쌓은 스레드와 작업 스레드가 달라서 데이터에 접근할 수 없다.","link":"/2021/12/03/book/%EC%8B%A4%EC%A0%84-%EC%8A%A4%ED%94%84%EB%A7%815%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/4-2/"},{"title":"4. 리액터 프로젝트 - 리액티브 앱의 기초","text":"리액티브 스트림 스펙은 리액티브 라이브러리가 서로 호환할 수 있게 해주며 여러 중요한 개선 사항이 많았지만 API 및 규칙만 정의하고 일상적인 사용을 위한 라이브러리는 제공하지 않았다. 리액티브 프레임워크중에서 가장 유명한 라이브러리 중 하나인 리액터 프로젝트(Project Reactor)는 1.x 버전에서 리액터 패턴, 함수형 프로그래밍 및 리액티브 프로그래밍과 같은 메시지 처리에 대한 모범 사례를 통합하여 비동기 논블로킹 처리를 지원하도록 설계하였다. 이후 여러 부족한 부분들을 보완하면서 2.x를 거쳐 현재는 3.x 버전으로 릴리즈되어있다. 리액터 프로젝트 필수 요소 비동기 파이프라인을 구축할 때 콜백 지옥과 깊게 중첩된 코드를 생략 코드 가독성을 높이고 리액터 라이브러리에 의해 정의된 워크플로에 **조합성(composability)**을 추가 리액터 API는 연산자를 연결해서 사용하는 것을 권장하며 이를 통해 복잡하고 재사용 가능한 실행 그래프(execution graph)를 작성할 수 있다. 그래프는 실행 흐름만 정의하며 구독자가 실제 구독을 했을 때만 데이터 플로가 기동된다. 오류 발생 가능성이 있는 비동기 요청의 결과를 효율적으로 처리하여 유연하지만 복원력 있는 코드를 작성할 수 있다. 배압은 리액티브 스트림 스펙의 핵심 속성으로 리액터 역시 동일하다. 123(데이터 플로)--▶️ --▶️ --▶️ 게시자 연산자 연산자 구독자 ◀️-- ◀️-- ◀️--(요청) 배압 전파의 일반적인 모드를 모두 지원 푸시 전용 : subscription.request(Long.MAX_VALUE) 풀 전용 : subscription.request(1) 풀-푸시(혼합형) : 구독자가 수요를 실시간으로 제어할 수 있고 게시자가 데이터 소비 속도에 적응할 수 있는 경우 풀-푸시 모델을 지원하지 않는 이전 API를 적용할 때는 예전 스타일의 배압 메커니즘을 제공한다. Flux와 Mono데이터를 기반으로 리액티브 스트림을 생성하는 팩토리 메서드를 제공 Mono는 Flux와 비슷하지만 하나의 요소를 대상으로 사용되는데 HTTP 요청이나 DB 쿼리와 같은 비동기 작업을 래핑하는데 매우 유용 Flux와 Mono는 구독 루틴을 단순화하는 subscribe() 메서드를 람다 기반으로 재정의한다. 12345678910111213Flux.just(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) .subscribe( data -&gt; log.info(&quot;onNext: {}&quot;, data), err -&gt; { /* ignored */ }, () -&gt; log.info(&quot;onComplete&quot;) );/*onNext: AonNext: BonNext: ConComplete*/ 또한 subscription으로 구독을 직접 제어하거나 직접 Subscriber 인터페이스를 구현하여 스트림을 구독할 수 있다. 연산자를 이용해 리액티브 시퀀스 변환하기연산자의 종류가 너무 많아서 적절한 연산자를 선택하는 가이드를 포함한 아래 링크를 참조 Which operator do I need? 원소 매핑 : map(1:1) … 필터링 : filter … 시퀀스 수집? 합치기? : collectList() … 원소 줄이기 : reduce, scan … 스트림 조합 : concat, merge, zip … 스트림 내의 원소 일괄 처리 buffer : List와 같은 컨테이너를 이용한 Buffering, Flux&lt;List&lt;T&gt;&gt; window : Flux&lt;Flux&lt;T&gt;&gt;와 같은 형태로 스트림을 스트림으로 Windowing groupBy : Flux&lt;GroupedFlux&lt;K, T&gt;&gt; 유형의 스트림으로 Grouping flatmap : 논리적으로 map과 flatten의 2가지 작업으로 구성 map파트는 들어오는 각 원소를 리액티브 스트림(T -&gt; Flux&lt;R&gt;)으로 변환 flatten파트는 생성된 모든 리액티브 시퀀스를 R 타입의 원소를 통과시키는 새로운 리액티브 시퀀스로 병합 샘플링 : sample 연산자를 사용하여 특정 기간 내 최근에 관찰된 값을 주기적으로 출력할 수 있다. 블로킹 구조로 전환 리액티브 애플리케이션에서 블로킹 처리를 해선 안되지만, 상위 API에서 필요로 하는 경우도 있음 blockFirst, blockLast, toIterable, toStream … Mono#toFuture 를 제외한 모든 메서드는 “non-blocking only”로 표시된 스케줄러에서 호출되면 UnsupportedOperatorException을 발생시킨다. 시퀀스 엿보기 doOnNext(Consumer &lt;T&gt;), doOnComplete(), doOnError(Throwable)… 최종 시퀀스를 수정하지 않고 프로세스 파이프라인의 중간에 있는 각 원소나 특정 시그널을 처리해야 하는 경우 Hot 스트림과 cold 스트림1. 콜드 퍼블리셔(cold publisher) 구독자가 나타날 때마다 시퀀스 데이터가 생성되는 방식 구독자 없이는 데이터 생성 X 대표적으로 HTTP 요청이 이런식으로 동작한다.2. 핫 퍼블리셔(hot publisher) 데이터 생성 시 구독자의 존재 여부에 의존하지 않는 방식 첫 구독자가 없더라도 원소를 만들어 낼 수 있다. 이때 구독자가 나타나면 이전 생성값 말고 새로운 값만 보낼 수도 있다. 리액터 라이브러리에 포함된 대부분은 Processor 인터페이스를 상속한다. 콜드 퍼블리셔를 리액티브 변환을 통해 핫 퍼블리셔로 전환할 수 있다.","link":"/2021/12/03/book/%EC%8B%A4%EC%A0%84-%EC%8A%A4%ED%94%84%EB%A7%815%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/4/"},{"title":"PostgreSQL 테이블 중복데이터 제거","text":"설계, 운영이 잘 되는 DB에선 많이 발생하는 문제는 아닐테지만 테이블의 특정 컬럼값을 기준으로 중복된 데이터를 삭제해야 하는 경우가 있다. 필자의 경우 PostgreSQL을 사용하던 중 이전 담당자가 테이블을 TEST_01_TB ~ TEST_10_TB 이런식으로 물리적으로 10개로 나눠서 설계하여 사용하던걸 인수받았는데 감리 검수에서 10개의 테이블을 하나로 합치라는 개선안내를 받았다. Hash Partition을 적용하여 테이블을 합쳤으나 파티션을 적용하니 기존에 복합키로 사용하던 Unique 조건이나 데이터를 생성 시 Insert쿼리문에서 ON CONFLICT 컬럼 DO NOTHING 옵션도 적용할 수 없어서 빠지게 되었는데 이 때문에 중복데이터가 발생하였다. 중복된 데이터를 어떻게 찾아서 지우느냐에 따라 수행시간에 큰 차이가 날거라고 생각해서 구글링을 해보니 몇가지 방법을 찾을 수 있었다. Test Table Schema 12345678910CREATE TABLE MEMBER_TB ( MEM_ID BIGSERIAL PRIMARY KEY, MEM_NAME VARCHAR(20) NOT NULL, MEM_PNUM VARCHAR(11) NOT NULL, MEM_EMAIL TEXT NOT NULL);CREATE TABLE BLACKLIST_TB ( MEM_PNUM VARCHAR(11) PRIMARY KEY); ROW_NUMBER() 유저 테이블에의 MEM_PNUM 컬럼을 기준으로 중복된 데이터가 있어서 이를 지우기 위해선 어떻게 해야할까? 구글링을 하고 제일먼저 찾은 방법은 ROW_NUMBER() 를 활용한 방법이었다. 1234567DELETE FROM MEMBER_TBWHERE MEM_ID IN ( SELECT MEM_ID FROM (SELECT MEM_ID, ROW_NUMBER() OVER(PARTITION BY MEM_PNUM ORDER BY MEM_ID ) RNUM FROM MEMBER_TB ) WHERE RNUM &gt; 1 ); 바로 적용할까 싶었지만 타겟 테이블의 데이터건수는 수십억개라 좀 더 빠른 방법이 없는지 더 찾아보던 중 Self Join과 Delete Using을 활용한 방법을 찾을 수 있었다. DELETE USING 특정 테이블을 참조하여 데이터를 삭제할 때 PostgreSQL의 경우 MySQL처럼 DELETE JOIN을 제공하진 않지만 USING을 사용하여 DELETE JOIN과 유사한 기능을 지원한다. 123DELETE FROM MEMBER_TB T1USING BLACKLIST_TB T2WHERE T1.MEM_PNUM = T2.MEM_PNUM; 예를 들면 이 처럼 USING 키워드를 사용하여 특정 테이블을 참조하여 유저테이블에서 블랙리스트 유저정보만 지울 수 있다. 그럼 여기서 SELF JOIN을 활용하여 MEM_PNUM, MEM_EMAIL 컬럼의 중복데이터를 삭제하고 싶으면 SQL문을 다음과 같은 식으로 작성할 수 있다. 12345DELETE FROM MEMBER_TB T1USING MEMBER_TB T2WHERE T1.CTID &lt; T2.CTID AND T1.MEM_PNUM = T2.MEM_PNUM AND T1.MEM_EMAIL = T2.MEM_EMAIL; 참고한 자료에선 1000만건의 데이터 중 10만건이 중복발생했을 때 약 42초정도 걸렸다고 했고 적용 전 확인해보기 위해 샘플로 Row가 약 800만에 중복데이터가 32만건 정도 들어있는 테이블로 테스트를 해보니 쿼리 실행에 약 1분정도 소요된 것을 확인하고 본래 타겟 테이블에 적용하였다. 그 후 데이터 생성 로직을 변경하여 중복데이터가 들어올 수 없도록 수정하였고 설계와 테스트를 더 잘 해야겠다는 생각이 절실하게 드는 하루였다. ReferencePostgreSQL DELETE JOIN 중복된 관측치 제거하기 How to delete duplicate rows in postgresql?","link":"/2020/11/23/sql/postgresql/%EC%A4%91%EB%B3%B5-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%9C%EA%B1%B0/"},{"title":"Docker Desktop for window 경로 변경","text":"회사pc에서 docker를 로컬에 설치해서 사용해볼 일이 있어서 설치를 하려는데 보안 프로그램 때문에 C드라이브에 제대로 설치가 안됐다. D드라이브에 설치를 하고 싶었는데 Docker Desktop for window 설치파일에서 설치경로를 바꾸는 옵션을 제공하지 않고 있는데 🔗 https://github.com/docker/roadmap/issues/94(최근까지도 기다리는 사람이 많은듯?) 도커포럼에서 해당 이슈에 대한 임시 해결책으로 링크를 생성해서 설치경로를 바꾸는 방법이 있었다. 🔗 https://forums.docker.com/t/docker-installation-directory/32773/11 docker 설치 전 cmd를 관리자모드로 실행하고 아래 명령어를 실행한다.(xxx = 본인 계정) 만약 이미 한번 설치를 해서 각 위치에 폴더가 이미 생성된 상태라 C드라이브 경로에 생성된 폴더들 다 지우고 명령어 실행하면 된다. (타겟 경로의 폴더들은 나중에 만들어줘도 됨) 1234mklink /j &quot;C:\\ProgramData\\Docker&quot; &quot;D:\\ProgramData\\Docker&quot;mklink /j &quot;C:\\ProgramData\\DockerDesktop&quot; &quot;D:\\ProgramData\\DockerDesktop&quot;mklink /j &quot;C:\\Program Files\\Docker&quot; &quot;D:\\Program Files\\Docker&quot;mklink /j &quot;C:\\Users\\xxx\\AppData\\Local\\Docker&quot; &quot;D:\\Users\\xxx\\AppData\\Local\\Docker&quot; 이후 installer를 실행해보면 로그에는 C드라이브에 설치하는거로 나오지만 실제 파일은 링크를 걸어놓은 D드라이브에 생성되는 모습을 볼 수 있다.","link":"/2022/01/08/docker/installation-directory/"},{"title":"Google Tag Manager 간단 정리","text":"웹사이트 또는 모바일 앱에서 태그라고 통칭되는 추적 코드 및 관련 코드 조각을 쉽고 빠르게 업데이트할 수 있는 태그 관리 시스템 여기서 태그는 웹페이지의 HTML 태그를 말하는게 아니고 마케팅 업계에서 자바스크립트로 데이터를 수집해서 웹 분석 및 광고 성과 추적용도로 사용하기 위해 서비스 제공업체(구글,네이버,페이스북 등)로 전달하는 역할을 수행하는 기능을 말한다. 컨테이너 코드 스니펫(컨테이너 생성 시 헤더, 바디에 심으라고 하는 코드)이라는 기본 스크립트를 소스코드에 한번 추가하면 이후 개발자가 관여하지 않더라도 GTM에서 제공하는 UI를 통해 태그를 효율적으로 추가,삭제,변경 등 관리하기 위해 사용한다. 1234567&lt;!-- Google Tag Manager --&gt;&lt;script&gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&amp;l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-A123456');&lt;/script&gt;&lt;!-- End Google Tag Manager --&gt; 컨테이너태그를 관리하는 프로젝트 단위로 일반적으로 도메인별로 생성하며 태그,트리거,변수 3가지 요소를 사용해서 데이터를 추적 변수(How)특정 값을 담아두는 가상의 메모리 영역으로 어떠한 데이터를 수집할 지 지정하고 여러 이벤트에서 재사용하여 효율증가 ex) 특정 페이지에 접속할때, 클릭할때 데이터를 수집할 경우 사전 정의된 url이라는 변수는 현재 로드중인 페이지의 URL을 변수로 사용할 수 있다. 트리거 : 태그 실행 조건을 지정하는 필터를 정의하는 용도 (ex: url 변수가 ‘example.com/index.html’일 때 페이지뷰 트리거를 실행하는 용도) 태그 : 동적 값을 포착하여 전송하는 데 변수가 사용 (ex: 거래 금액과 구매 제품을 전환추적 태그에 전달하는 용도) 기본 제공하는 변수로 처리할 수 없는 특정 요구사항에 맞추고 싶다면 사용자 정의 변수를 생성할 수 있다. 트리거(When)태그(명령어)가 실행되는 조건을 정의하여 조건 충족 시 연결된 태그가 실행 ex) 페이지뷰, 클릭할때 등 이벤트 실행 조건 태그(What)데이터를 추적하여 수집하기 위해 명령하는 명령어의 역할로 트리거의 조건이 충족되면 태그가 인식하여 데이터를 추적하여 Google Analytics 등의 툴에서 데이터를 수집 쉽게 생각해서 트리거가 실행 조건을 담고 있고 태그는 실행 내용을 담고 있다고 생각하면 된다. 데이터 영역(dataLayer)웹사이트에서 태그 관리자 컨테이너로 정보를 전달할 때 사용되는 자바스크립트 객체 웹사이트 –&gt; dataLayer &lt;–&gt; GTM –&gt; 구글 애널리틱스, 네이버광고 등 구글 애널리틱스 사용 시 전자상거래 구매 데이터, 맞춤 측정기준에서 사용하는 데이터 등은 기본 추적코드만으로는 수집할 수 없어 추가적인 설정이 필요하다. 이때 주로 웹페이지 내 별도의 추적 코드를 소스코드에 삽입하여 이들 정보를 GA서버로 직접 보내는 방식을 사용하는데 GTM에선 이런 정보를 수집할 때 데이터 영역을 주로 사용한다. 코드 스니펫을 header에 추가하고 123&lt;script&gt; window.dataLayer = window.dataLayer || [];&lt;/script&gt; dataLayer.push() 명령어를 사용하면 데이터 영역에 정보를 추가할 수 있다. 12345&lt;a href=&quot;#&quot; onclick=&quot;dataLayer.push({ 'bookCategory': 'fiction', 'bookTitle': 'Cien años de soledad', 'bookAuthor': 'Gabriel García Márquez'});&quot;&gt;도서 세부정보&lt;/a&gt; 주의사항으로 GTM은 컨테이너 스니펫 실행 시 자동으로 데이터영역을 생성하며 이미 있는 경우 그 안의 변수를 가져다 사용하기 때문에 데이터영역은 GTM 컨테이너 스니펫보다 앞에 위치해야 한다고 한다. 그 외 태그,트리커,변수 생성 과정에 대한 자세한 방법은 아래 링크 참고 구글-태그-관리자-설치-및-사용법 태그, 트리거, 변수에서 설정가능한 유형에 대해선 태그 관리자 고객센터에서 각 항목 참고 태그 관리자 고객센터","link":"/2021/12/13/etc/gtm-1/"},{"title":"1. 계층형 아키텍처의 문제는 무엇일까?","text":"계층형 아키텍처란?계층(layer)으로 구성된 (웹) 애플리케이션은 전통적인 웹 애플리케이션 구조를 말한다. 크게보면 웹 → 도메인 → 영속성 으로 구성된 3계층으로 많이 표현되는데 웹 : 요청을 받아서 서비스로 요청을 보냄 도메인(비즈니스) : 필요한 비즈니스 로직을 수행하고 엔티티의 현재 상태를 조회하거나 변경하기 위해 영속성 계층의 컴포넌트 호출 영속성 : 엔티티, 리포지터리 등 데이터베이스 관련 컴포넌트 오랫동안 사용한만큼 견고한 아키텍처 패턴이 맞고 잘 이해하고 사용하면 각 계층에 독립적으로 로직을 작성하고 기존 기능에 영향없는 기능 추가도 가능하다. 다만, 계층형은 코드에 나쁜 습관들이 스며들기 쉽고 시간이 지날수록 유지보수가 힘들어지는 단점들이 있다. 계층형 아키텍처는 데이터베이스 주도 설계를 유도한다.계층형의 토대는 데이터베이스라서 웹은 도메인을, 도메인은 영속성을 의존하다보니 모두 데이터베이스에 의존하게 된다. 보통 애플리케이션을 만들때 비즈니스를 관장하는 규칙이나 정책을 반영한 모델을 만드는데 이때 우리는 상태(state)가 아니라 행동(behavior)을 중심으로 모델링한다. 하지만 계층형의 설계는 보통 데이터베이스를 토대로 도메인 로직을 구현하는 방식이라서 아키텍처의 구현으로는 맞더라도 비즈니스 관점에선 다르다. 가장 중요한 도메인 로직을 먼저 만들어야 로직을 제대로 이해하는지 확인하고 이를 토대로 웹과 영속성 계층을 설계할 수 있기 때문이다. ORM(object-relational-mapping, 객체 관계매핑) 프레임워크(JPA, 하이버네이트 등)를 사용하면 비즈니스 규칙을 영속성 관점에 섞고 싶은 생각이 들게 된다. ORM에 의해 관리되는 엔티티들은 일반적으로 영속성 계층에 두고 도메인계층에선 엔티티에 접근가능한데 이러한 구조는 영속성 계층과 도메인 계층 사이에 강한 결합을 만들게 된다. 서비스에서 영속성 모델을 마치 비즈니스 모델처럼 사용하다보면 도메인 로직뿐만 아니라 영속성 계층과 관련된 작업들도 해줘야 한다. 영속성 코드가 사실상 도메인 코드에 녹아들면서 둘 중 하나만 바꾸는게 어려워져서 계층형의 목표와 대치되는 코드가 된다. 지름길을 택하기 쉬워진다.계층형 아키텍처는 특정한 계층에서는 같은 계층에 있는 컴포넌트나 아래에 있는 계층에만 접근 가능하다는 규칙이 있다. 만약 상위 계층에 위치한 컴포넌트에 접근해야 한다면? 컴포넌트를 계층 아래로 내려버리면 된다. 한번은 괜찮을 수 있다. 근데 2번, 3번이 넘고 나 뿐만 아니라 다른 동료들도 그렇게 하게 되면? 유틸리티나 헬퍼 컴포넌트 등이 아래 계층으로 내려오게 되면 영속성 계층은 모든 것에 접근 가능하기 때문에 시간이 지날 수록 점점 비대해 질 것이다. 테스트하기 어려워진다.계층형 아키텍처에서 계층을 건너뛰도록 하는 경우도 있다. 엔티티의 필드를 딱 하나만 조작하면 될 경우에 웹 계층에서 바로 영속성 계층에 접근하면 도메인 계층을 건너 뛰게 된다. 이런 경우 크게 두가지 문제가 발생하는데 도메인 로직을 웹 계층에 구현하게 된다.만약 유스케이스가 확장된다면 더 많은 도메인 로직이 웹 계층에 추가되면서 애플리케이션 전반으로 책임이 섞이고 핵심 도메인 로직들이 퍼져나갈 수 있다. 웹 계층 테스트에서 도메인 계층뿐만 아니라 영속성 계층도 모킹(mocking)해야 한다.이 경우 단위 테스트의 복잡도가 올라가고 이렇게 복잡한 설정을 할 시간이 없어서 테스트를 안하게 되는 시작이 된다. 유스케이스를 숨긴다.기능을 추가하거나 변경할 적절한 위치를 찾는 일이 빈번하기 때문에 ㅐ아키텍처는 코드를 빠르게 탐색하는데 도움이 돼야 한다. 계층형 아키텍처에서는 도메인 로직이 여러 계층에 걸쳐 흩어지기 쉬운 환경이라 유스케이스가 “간단”해서 도메인 계층을 생략하면 웹 계층에 존재할 수도 있고, 도메인과 영속성 모두에 접근할 수 있도록 컴포넌트의 계층을 내리면 영속성 계층에 존재할 수도 있다. 이런 경우 새로운 기능을 추가할 적당한 위치를 찾기 어려워지고 여러 개의 유스케이스를 담당하는 아주 넓은 서비스가 만들어질 수도 있다. 넓은 서비스는 영속성 계층에 많은 의존성을 갖게되고, 웹 레이어의 많은 컴포넌트가 이 서비스에 의존하게 된다. 서비스는 점점 더 복잡해지고 테스트하기도 어려워진다. 동시 작업이 어려워진다.새로운 기능을 추가하기 위해 3명의 개발자가 있을때 각 계층에 각각의 기능을 동시에 개발할 수 있을까? 계층형에선 영속성 계층 위에 모든 것이 만들어지기 때문에 영속성 계층을 먼저 개발ㄹ해야 하고, 그 다음에 도메인 계층, 웹 계층을 만들어야 한다. 동시에 한꺼번에가 아니라 한번에 한명의 개발자만 일할 수 있는 것이다. 또한 넓은 서비스가 있다면 서로 다른 기능을 동시에 작업하기 어려운데 병합 충돌(merge conflict)이나 롤백이 필요한 문제가 발생할 수 있다. 유지보수 가능한 소프트웨어를 만드는 데 어떻게 도움이 될까?올바르게 구축하고 몇 가지 추가적인 규칙들을 잘 적용한다면 계층형 아키텍처는 유지보수하기 매우 쉬워지며 코드를 쉽게 변경하거나 추가할 수 있다. 하지만 잘못된 방향으로 흘러가기 쉽다보니 계층형 아키텍처로 만들든 다른 아키텍처 스타일로 만들든, 지름길을 택하지 않고 유지보수하기에 더 쉬운 솔루션을 만드는 데 도움이될 것이다.","link":"/2023/02/25/book/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/clean-1/"},{"title":"2. 의존성 역전하기","text":"계층형 아키텍처의 대안을 이야기 하기전에 SOLID 원칙의 ‘S’와 ‘D’를 담당하는 아래 원칙들을 먼저 살펴보자. 단일 책임 원칙(Single Responsibility Principle, SRP) 하나의 컴포넌트는 오로지 한 가지 일만 해야 하고, 그것을 올바르게 수행해야 한다. 이 말은 실제 의도와는 조금 다른 오해가 발생할 여지가 있으니 아래 정의가 좀 더 정확하다고 볼 수 있다. 컴포넌트를 변경하는 이유는 오직 하나뿐이어야 한다. 만약 컴포넌트를 변경할 이유가 한 가지라면 우리가 “어떤 다른 이유로” 소프트웨어를 변경하더라도 이 컴포넌트에 대해선 전혀 신경 쓸 필요가 없다. 하지만 변경할 이유라는건 컴포넌트 간의 의존성을 통해 너무 쉽게 전파된다.A 컴포넌트는 B,C,D,E에 의존하고 E는 다른 의존성이 없다면A는 다른 B,C,D,E가 바뀔 때 함께 바뀌어야 하지만 E는 E에 기능이 추가,변경될 때만 바뀌게 될 것이다. 의존성 역전 원칙(Dependency Inversion Principle, DIP)계층형에서 계층 간 의존성은 항상 다음 계층인 아래 방향을 가리킨다. 단일 책임 원칙을 고수준에서 적용할 경우 상위 계층들이 하위 계층들에 비해 변경할 이유가 더 많다. 그러므로 영속성 계층에 대한 도메인 계층의 의존성 때문에 영속성 계층을 변경할 때마다 잠재적으로 도메인 계층도 변경해야 한다. 하지만 도메인 코드는 애플리케이션에서 가장 중요한 코드인데 영속성 코드가 바뀐다고 도메인 코드까지 바꾸는게 맞을까? 이 의존성은 어떻게 제거할 수 있을까? 의존성 역전 원칙은 말 그대로의 의미이다. 코드 상의 어떤 의존성이든 그 방향을 바꿀 수(역전시킬 수) 있다. 단, 서드파티 라이브러리처럼 제어할 수 없는 코드에 의존성을 가지고 있다면 역전이 불가능하다. 일반적으로 보기 쉬운 계층형 구조의 서비스가 있다. 도메인 계층의 서비스는 영속성 계층의 엔티티와 리포지토리와 상호작용한다. 엔티티는 도메인 객체를 표현하고 도메인 코드는 이러한 엔티티의 상태를 변경하는 일을 중심으로 하니까 일단 엔티티를 도메인 계층으로 올려보면 영속성의 리포지토리가 도메인의 엔티티를 의존하는 순환의존성이 생기게 된다. 여기서 DIP를 적용하면 도메인 계층에 리포지토리에 대한 인터페이스를 만들고, 실제 리포지토리는 영속성 계층에서 구현하게 하는 것이다. 이제 도메인 계층에 인터페이스를 도입함으로써 의존성을 역전시켜서 도메인 로직은 영속성 코드에 의존하지 않고 영속성 계층이 도메인 계층에 의존하게 된다. 클린 아키텍처도메인 코드가 바깥으로 향하는 어떤 의존성도 없어야 함을 의미한다. 대신 의존성 역전 원칙의 도움으로 모든 의존성이 도메인 코드를 향하고 있다. 클린 아키텍처의 코어에는 주변 유스케이스에서 접근하는 도메인 엔티티들이 있다. 유스케이스는 서비스를 의미하는데 단일 책임을 갖기 위해 좀 더 세분화 시켜서 넓은 서비스 문제를 피한다. 도메인 코드에선 어떤 영속성 프레임워크나 UI 프레임워크가 사용되는지 알 수 없기 때문에 특정 프레임워크에 특화된 코드를 가질 수 없고 비즈니스 규칙에 집중할 수 있어서 자유롭게 모델링할 수 있다. 다만, 도메인 계층이 영속성이나 UI 같은 외부 계층과 철저하게 분리돼야 하므로 애플리케이션의 엔티티에 대한 모델을 각 계층에서 유지보수 해야 한다. 영속성에서 ORM을 사용하는 경우, 도메인 계층과 영속성 계층이 데이터를 주고받을 때, 두 계층에 각각 엔티티 클래스를 만들어서 서로 변환해야 하는데 이는 바람직한 방향이다. 특정 프레임워크에 특화된 문제로부터 해방시키고자 했던, 결합이 제거된 상태이다. 클린 아키텍처는 약간 추상적인 느낌이 강해서 이 원칙들을 좀 더 구체적으로 만들어주는 ‘육각형 아키텍처(헥사고날 아키텍처)’에 대해서 살펴보자. 육각형 아키텍처(헥사고날 아키텍처)애플리케이션 코어가 각 어댑터와 상호작용하기 위해 특정 포트를 제공하기 때문에 ‘포트와 어댑터 아키텍처라고도 불린다. 꼭 육각형의 모양이 중요한건 아니고 팔각형이어도 상관없다. 육각형 안에는 도메인 엔티티와 이와 상호작용하는 유스케이스가 있다. 외부로 향하는 의존성이 없고 모든 의존성은 코어를 향한다. 육각형 바깥에는 웹 브라우저와 상호작용하는 웹 어댑터, 데이터베이스와 상호작용하는 영속성 어댑터, 외부 시스템와 상호작용하는 어댑터 등 애플리케이션과 상호작용하는 다양한 어댑터들이 있다. 코어와 어댑터들 간의 통신이 가능하려면 애플리케이션 코어가 각각의 포트를 제공해야 한다. 주도하는 어댑터에게는 포트가 코어에 있는 유스케이스 클래스들에 의해 구현되고 호출되는 인터페이스가 될 것이고, 주도되는 어댑터에는 어댑터에 의해 구현되고 코어에 의해 호출되는 인터페이스가 될 것이다. 이러한 아키텍처의 목적은 결국 도메인 코드가 바깥쪽 코드에 의존하지 않게 함으로써 영속성과 UI에 특화된 모든 문제로부터 도메인 로직의 결합을 제거하고 코드를 변경할 이유의 수를 줄이는 효과가 있다.","link":"/2023/03/01/book/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/clean-2/"},{"title":"3. 코드 구성하기","text":"코드만 보더라도 어떤 아키텍처인지 알 수 있다면 좋지 않을까? 보통 새로운 프로젝트를 시작할 때 가장 먼저 패키지 구조를 설계하게 된다. 계층으로 구성하기기본적인 계층형으로 프로젝트를 생성한다면 아래와 같은 구조가 될 것이다. 12345678910buckpal ├─domain │ ├─Account │ ├─Activity │ ├─AccountRepository │ └─AccountService ├─persistence │ └─AccountRepositoryImpl └─web └─AccountController 도메인, 웹, 영속성 계층별로 패키지를 만들었고 앞서 나왔던 의존성 역전을 사용하여 domain 패키지에 AccountRepository 인터페이스를 두고 persistence 패키지에 구현체를 둬서 의존성이 도메인을 바라보도록 구성되어있다. 다만 몇가지 단점이 보이는데 기능이나 특성을 구분짓는 패키지의 경계가 없다. 새로운 기능(ex) 사용자관리)을 추가하려면 각 계층 패키지에 UserController, UserService, User 등을 추가하게 되는데 다른 기능과 섞이게 되면 예상치 못한 부수효과가 발생할 수 있다. 애플리케이션이 어떤 유스케이스를 제공하는지 파악하기 어렵다. AccountController와 AccountService가 구체적으로 어떤 기능을 제공하는지 파악하려면 내부 구현 메서드를 살펴봐야 한다. 패키지만 봐서 의도하는 아키텍처를 짐작하기 어렵다. 육각형 아키텍처라고 추측하고 웹 어댑터와 영속성 어댑터를 찾기 위해 web, persistence 패키지를 조사해볼 순 있지만 어떤 기능이 웹어댑터에서 호출되는지, 영속성 어댑터가 도메인 계층에 어떤 기능을 제공하는지 한눈에 알 수 없다. 인커밍 포트와 아웃고잉 포트가 코드 속에 숨겨져 있다. 기능으로 구성하기1234567buckpal └─account ├─Account ├─AccountController ├─AccountRepository ├─AccountRepositoryImpl └─SendMoneyService 계좌 관련 기능을 모두 account 라는 패키지에 모았고 AccountService도 책임을 좁히기 위해서 SendMoneyService로 변경하였다. 이렇게 되면 ‘송금하기’ 유스케이스를 구현한 코드는 클래스명만 봐도 바로 찾을 수 있다. 하지만 기능을 기준으로 코드를 구성하면 기반 아키텍처가 명확하게 보이지 않아서 가시성이 많이 떨어진다는 큰 단점이 있다. 아키텍처적으로 표현력 있는 패키지 구조육각형 아키텍처에서 구조적으로 핵심적인 요소는 엔티티, 유스케이스, 인커밍/아웃고잉 포트, 인커밍/아웃고잉(혹은 주도하거나 주도되는) 어댑터이다. 123456789101112131415161718192021buckpal └─account ├─adapter │ ├─in │ │ └─web │ │ └─AccountController │ ├─out │ └─persistence │ ├─AccountPersistenceAdapter │ └─SpringDataAccountRepository ├─domain │ ├─Account │ └─Activity └─application ├─SendMoneyService └─port ├─in │ └─SendMoneyUseCase └─out ├─LoadAccountPort └─UpdateAccountStatePort 도메인 모델이 속한 domain 패키지와 도메인 모델을 둘러싼 서비스 계층을 포함하는 application패키지가 있다. SendMoneySerivce는 인커밍 포트 인터페이스인 SendMoneyUseCase를 구현 아웃고잉 포트 인터페이스이자 영속성 어댑터에 의해 구현된 LoadAccountPort와 UpdateAccountStatePort를 사용한다. adapter 패키지는 애플리케이션 계층의 인커밍 포트를 호출하는 인커밍 어댑터와 애플리케이션 계층의 아웃고잉 포트에 대한 구현을 제공하는 아웃고잉 어댑터를 포함한다. 책을 읽다가 곰곰히 생각해 봤지만 패키지의 구조가 표현력이 있긴한데 아직 익숙치 않아서 한눈에 들어오진 않는다. 다만, 팀원들과 이러한 아키텍처에 대한 논의가 충분히 되고 합의된 상태에서 구조를 잡는다면 코드와 아키텍처가 직접적으로 매핑되면서 추상적이던 아키텍처가 좀 더 구체적으로 파악이 가능해진거 같기도 하다.","link":"/2023/03/01/book/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/clean-3/"},{"title":"4. 유스케이스 구현하기","text":"앞서 설계한 패키지대로 코드를 작성하면 애플리케이션, 웹, 영속성 계층이 아주 느슨하게 결합돼 있기 때문에 필요한 대로 도메인 코드를 자유롭게 모델링할 수 있다. 육각형 아키텍처는 도메인 중심의 아키텍처에 적합하기 때문에 도메인 엔티티를 만드는 것으로 시작한 후 해당 도메인 엔티티를 중심으로 유스케이스를 구현한다. 유스케이스 둘러보기유스케이스는 일반적으로 아래와 같은 단계를 따른다. 입력을 받는다 비즈니스 규칙을 검증한다 모델 상태를 조작한다 출력을 반환한다. 유스케이스는 인커밍 어댑터로부터 입력을 받는데 유스케이스 코드는 도메인 로직에만 집중하고 ‘입력 유효성 검증’은 다른 곳에서 처리하는게 좋다. 그러나 유스케이스는 비즈니스 규칙을 검증할 책임이 있고 도메인 엔티티와 이 책임을 공유한다. 입력 유효성 검증입력 유효성 검증이 유스케이스의 책임이 아니라도 애플리케이션 계층의 책임은 맞다. 유효성 검증을 하지 않으면 애플리케이션 코어의 바깥쪽으로부터 유효하지 않은 입력값을 받게 되고, 모델의 상태를 해칠 수 있다. 입력 모델(input model)에서 이러한 검증을 담당해보자. 유스케이스에서 입력에 사용할 모델 클래스의 생성자 내에서 특정 조건에 위배될 경우 객체 생성 자체를 막고 예외를 던지면 될 것이다. 또한 필드에 final을 붙여서 불변 필드로 만들어 생성에 성공하면 유효한 상태를 유지하고 잘못된 상태로 변경할 수 없다는 사실을 보장할 수 있다. 사실 이런 기능들은 Bean Validation API를 사용하면 편하게 사용할 수 있다. 1234567891011@Getterpublic class SendMoneyCommand extends SelfValidating&lt;SendMoneyCommand&gt; { @NotNull private final Money; public SendMoneyCommand(Money money){ this.money = money; requiredGreaterThan(money, 0); this.validateSelf(); }} SelfValidating 추상 클래스는 validateSelf() 메서드를 제공하여 호출하면 필드에 지정된 Bean Validation 어노테이션(@NotNull 같은)을 검증하고 유효성 검증 규칙을 위반한 경우 예외를 던진다. 생성자의 힘필드가 많아질 경우 빌더패턴을 도입해서 생성자를 private으로 만들고 빌더의 build() 메서드 내부에 생성자 호출을 숨길 수 있다. 다만, 만약 빌더와 생성자에 새로운 필드를 추가하고 빌더를 호출하는 코드에 새로운 필드를 추가하는 걸 깜빡하더라도 컴파일러는 이러한 시도에 대해서 경고해주지 못할 수 있다. 빌더 뒤에 숨기지 말고 생성자를 직접 사용했다면 컴파일 에러에 따라 나머지 코드에 변경사항을 반영할 수 있을 것이다. 난 저자랑 생각이 다름 저자가 예시에서 파라미터가 20개인 생성자를 호출하는 대신 빌더를 사용하면 이러이러 하다 라고 말했는데 코드의 가독성 측면에서 빌더패턴이 훨씬 보기 좋다고 생각한다. 빌더 호출 코드에 깜빡할 경우가 얼마나 될것이며 단위테스트 과정에서 어느정도 걸러낼 수 있다고 생각된다. 오히려 생성자의 파라미터 20개가 모두 String 타입일 경우 지저분한 코드를 보는게 더 스트레스 받을거 같다. 유스케이스마다 다른 입력 모델각기 다른 유스케이스에 동일한 모델을 사용하고 싶은 경우가 있다. 계좌 등록하기와 계좌 업데이트 하기라는 두개의 기능을 구현할 때 계좌에 대한 등록시점에선 소유권을 체크하기 위해 계좌의 소유자 ID 필드가 무조건 필요하지만 업데이트는 계좌번호만 체크한다고 했을때 ID 필드는 null을 허용하도록 만들수 있다. 일단 불변 도메인 모델에 null을 허용하는 것부터 일단 코드 스멜이 난다고 볼수 있다.(잠재적으로 side-Effect가 발생할수도 있는 코드를 말한다.) 단일책임원칙을 고려했을 때 각 유스케이스의 전용 입력모델을 사용하는게 결합도도 낮추고 부수효과도 줄일 수 있는 방법이다. 다만, 모든 입력 데이터에 대해서 각 유스케이스 별 모델 매핑을 해줘야하는 비용이 있지만 매핑 전략에 대해선 후술 한다. 비즈니스 규칙 검증하기검증은 크게 두가지를 생각해볼 수 있다. 입력 유효성 검증 비즈니스 규칙 검증 둘을 구분하는 가장 실용적인 방법은 특정 검증이 도메인의 상태에 접근이 필요한지? **를 생각해보면 된다. 가령 단순히 입력 데이터의 유효성 체크는 도메인의 상태를 체크할 필요 없이 선언적으로 검증이 가능하지만 비즈니스 규칙은 좀 더 맥락을 이해하고 구현할 필요가 있다. “출금계좌는 초과출금될 수 없다.” 라는 규칙을 검증할땐 출금계좌의 존재여부 부터 체크하는 등 도메인의 상태에 접근해야 하지만”출금금액은 0보다 커야한다.” 라는 규칙은 도메인의 상태에 접근없이 입력 데이터를 단순히 체크하기만 하면 된다 비즈니스 규칙 검증은 보통 도메인 엔티티 내부에 직접 구현하는게 가장 좋다. 123456789public class Account { //... public boolean withDraw(Money money, AccountId targetAccountId) { if(!mayWithDraw(money)){ return false; } //... }} 이렇게 하면 지켜야하는 비즈니스 로직 옆에 있기 때문에 위치를 정하기도, 추론하기도 쉽다. 만약 엔티티 내부에 위치하기 어렵다면 유스케이스에서 도메인을 사용하기 전에 검증하는 방식도 있을 것이다. 1234567891011@RequriedArgsConstruct@Transactionalpublic class SendMoneyService implements SendMoneyUseCase { //... @Override public void SendMoney(SendMoneyCommand command){ requriedSourceAccount(command.getSourceAccountId()); requriedTargetAccount(command.getTargetAccountId()); //... }} 유효성 검증 코드를 실행 후 오류가 발생하면 유효성 전용 예외처리를 통해 사용자 풍부한 도메인 모델 vs 빈약한 도메인 모델 풍부한 도메인 모델 : 애플리케이션의 코어에 있는 도메인 엔티티에 최대한 많은 로직이 담겨있다. 도메인의 상태를 변경하는 메서드를 제공하고 비즈니스 규칙 검증에 유효한 값만 허용한다. 빈약한 도메인 모델 : 도메인 엔티티는 최대한 적은 로직을 가지고 있다. 보통 getter, setter를 제외한 다른로직은 모두 유스케이스에 구현한다. 결국 복잡한 비즈니스 모델이 어디에 있냐의 차이로 스타일의 차이라고 봐도 무방할 거 같다. 유스케이스마다 다른 출력모델입력에 대한 처리가 끝나면 출력을 해야하는데 이때도 동일하게 각 유스케이스마다 다른 출력모델을 사용하는게 좋다. 어떤 출력에선 Account 모델 자체를 받고 싶어할 수도 있고, 단순히 성공실패 여부 등 boolean 값만을 받고 싶을 수도 있다. 정답은 없지만 명확한 규칙이 없다면 최대한 작은 데이터를 반환하는게 좋다. 모델 클래스를 통째로 반환하면 강한 결합이 일어나는데 한 유스케이스의 출력 모델에 새로운 필드가 추가될 경우 동일한 모델을 공유하는 다른 유스케이스에서도 해당 필드를 처리해야 하는 것처럼 영향이 있기 때문에 모델은 구체적이고 작게 결합은 약하게 하는게 좋다. 같은 이유로 도메인 엔티티 자체를 출력모델로 사용하는 것도 최대한 자제해야한다. 읽기 전용 유스케이스는 어떨까?상태를 변경할 필요 없이 단순히 DB를 조회해서 값을 반환하기만 하는 읽기 전용 유스케이스를 구현해야 할때 상태변경 유스케이스와 동일한 형식으로 만들게 되면 간단한 기능에 비해 구현해야하는 것들이 많아질 수 있다. 간단히 쿼리만 조회해야 한다면 쿼리 서비스를 만들 수 있다. 인커밍 전용 포트를 만들어서 쿼리 서비스에서 구현하는 것이다. 12345678910@RequiredArgsConstructorpublic class GetAccountQueryService implements GetAccountBalanceService { private final LoadAccountPort loadAccountPort; @Override public Money getAccountBalance(AccountId accountId) { return loadAccountPort.loadAccount(accountId, LocalDateTime.now()) .calculateBalance(); }} 쿼리서비스는 유스케이스 서비스와 동일한 방식으로 동작하는데 GetAccountBalanceQuery 라는 인커밍 포트를 구현하고, 데이터베이스로부터 실제로 데이터를 로드하기 위해 LoadAccountPort라는 아웃고잉 포트를 호출한다. 이처럼 읽기 전용 쿼리는 쓰기가 가능한 유스케이스(or 커맨드)와 코드 상에서 명확히 구분되는데 이런 방식은 CQS(Command-Query Separation)나 CQRS(Command-Query Responsibility Segregation) 같은 개념과 잘 맞는다.","link":"/2023/03/05/book/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/clean-4/"}],"tags":[{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"programmers","slug":"programmers","link":"/tags/programmers/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"월간코드챌린지","slug":"월간코드챌린지","link":"/tags/%EC%9B%94%EA%B0%84%EC%BD%94%EB%93%9C%EC%B1%8C%EB%A6%B0%EC%A7%80/"},{"name":"kakao","slug":"kakao","link":"/tags/kakao/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"open graph","slug":"open-graph","link":"/tags/open-graph/"},{"name":"kakaotalk","slug":"kakaotalk","link":"/tags/kakaotalk/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"functional","slug":"functional","link":"/tags/functional/"},{"name":"interview","slug":"interview","link":"/tags/interview/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"JWT","slug":"JWT","link":"/tags/JWT/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"book","slug":"book","link":"/tags/book/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"postgresql","slug":"postgresql","link":"/tags/postgresql/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"googleTagManager","slug":"googleTagManager","link":"/tags/googleTagManager/"}],"categories":[{"name":"algorithm","slug":"algorithm","link":"/categories/algorithm/"},{"name":"programmers","slug":"algorithm/programmers","link":"/categories/algorithm/programmers/"},{"name":"blog","slug":"blog","link":"/categories/blog/"},{"name":"functional","slug":"functional","link":"/categories/functional/"},{"name":"interview","slug":"interview","link":"/categories/interview/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"web","slug":"web","link":"/categories/web/"},{"name":"book","slug":"book","link":"/categories/book/"},{"name":"스프링부트와 AWS로 혼자 구현하는 웹서비스","slug":"book/스프링부트와-AWS로-혼자-구현하는-웹서비스","link":"/categories/book/%EC%8A%A4%ED%94%84%EB%A7%81%EB%B6%80%ED%8A%B8%EC%99%80-AWS%EB%A1%9C-%ED%98%BC%EC%9E%90-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%EC%9B%B9%EC%84%9C%EB%B9%84%EC%8A%A4/"},{"name":"실전! 스프링5를 활용한 리액티브 프로그래밍","slug":"book/실전-스프링5를-활용한-리액티브-프로그래밍","link":"/categories/book/%EC%8B%A4%EC%A0%84-%EC%8A%A4%ED%94%84%EB%A7%815%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"},{"name":"sql","slug":"sql","link":"/categories/sql/"},{"name":"postgresql","slug":"sql/postgresql","link":"/categories/sql/postgresql/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"etc","slug":"etc","link":"/categories/etc/"},{"name":"만들면서 배우는 클린 아키텍처","slug":"book/만들면서-배우는-클린-아키텍처","link":"/categories/book/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%ED%81%B4%EB%A6%B0-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"}]}